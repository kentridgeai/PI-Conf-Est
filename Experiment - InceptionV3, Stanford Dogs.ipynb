{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e3a8804",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 08:39:36.896379: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-04-09 08:39:36.896463: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-04-09 08:39:36.897796: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-04-09 08:39:36.904902: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "from tensorflow.keras.saving import register_keras_serializable\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.pmi_estimators import train_critic_model, neural_pmi\n",
    "from src.psi_estimators import psi_gaussian_train, psi_gaussian_val_class\n",
    "from src.pvi_estimators import train_pvi_null_model, neural_pvi_class, neural_pvi_ensemble_class\n",
    "import src.utils as utils\n",
    "import src.metrics as metrics\n",
    "import src.methods as methods\n",
    "import src.temp_scaling as temp_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "239d25ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-09 08:39:40.038238: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78835 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:0f:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model_name = 'inceptionv3'\n",
    "dataset_name = 'stanford-dogs'\n",
    "\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'stanford_dogs',\n",
    "    split=['train[:85%]', 'train[85%:]', 'test'],\n",
    "    data_dir = '../tensorflow_datasets/',\n",
    "    shuffle_files=False,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "IMG_SIZE = 224\n",
    "num_classes = 120\n",
    "def preprocess(image, label):\n",
    "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess)\n",
    "ds_val = ds_val.map(preprocess)\n",
    "ds_test = ds_test.map(preprocess)\n",
    "\n",
    "# batch_size = 128\n",
    "# ds_train = ds_train.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "# ds_val = ds_val.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "# ds_test = ds_test.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "true_y_train = np.argmax([y for x,y in ds_train], axis=1)\n",
    "true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "true_y_test = np.argmax([y for x,y in ds_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5ee96257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class_counts = np.zeros(120)\n",
    "# for _, label in tfds.as_numpy(ds_train.unbatch()):\n",
    "#     class_index = np.argmax(label)\n",
    "#     class_counts[class_index] += 1\n",
    "\n",
    "# class_weights = 1.0 / class_counts\n",
    "# class_weights = class_weights / np.sum(class_weights) * 10\n",
    "\n",
    "# class_weights_tensor = tf.constant(class_weights, dtype=tf.float32)\n",
    "\n",
    "# @register_keras_serializable()\n",
    "# def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "#     weights = tf.reduce_sum(class_weights_tensor * y_true, axis=1)\n",
    "#     unweighted_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "#     return weights * unweighted_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c95257f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=Input(shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "    x = GlobalAveragePooling2D()(base_model.output)\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    outputs = Dense(120, activation='linear')(x)\n",
    "    model = Model(inputs=base_model.input, outputs=outputs)\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = True\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe72d12",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9293199",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "\n",
    "    model = create_model()\n",
    "        \n",
    "    def weighted_categorical_crossentropy(y_true, y_pred):\n",
    "        weights = tf.reduce_sum(class_weights_tensor * y_true, axis=1)\n",
    "        unweighted_loss = tf.keras.losses.categorical_crossentropy(y_true, y_pred, from_logits=True)\n",
    "        return weights * unweighted_loss\n",
    "    \n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-4), loss=weighted_categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
    "    history = model.fit(ds_train, validation_data=ds_val, epochs=100, callbacks=[lr_scheduler, early_stop])\n",
    "    \n",
    "    if not os.path.exists(exp_name+'/saved_models'):\n",
    "        print(\"Making directory\", exp_name+'/saved_models')\n",
    "        os.makedirs(exp_name+'/saved_models')\n",
    "\n",
    "    model.save_weights(f'{exp_name}/saved_models/trained_weights.h5')\n",
    "    with open(f'{exp_name}/history.pickle', 'wb') as f:\n",
    "        pickle.dump(history, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3843a2b6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-4), loss=weighted_categorical_crossentropy, metrics=['accuracy'])\n",
    "    train_acc.append(model.evaluate(ds_train, verbose=1)[1])\n",
    "    val_acc.append(model.evaluate(ds_val, verbose=1)[1])\n",
    "    test_acc.append(model.evaluate(ds_test, verbose=1)[1])\n",
    "print(f'Average train error: {(100-np.mean(train_acc)*100):.2f} ({(np.std(train_acc)*100):.2f})')\n",
    "print(f'Average validation error: {(100-np.mean(val_acc)*100):.2f} ({(np.std(val_acc)*100):.2f})')\n",
    "print(f'Average test error: {(100-np.mean(test_acc)*100):.2f} ({(np.std(test_acc)*100):.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506ff60c",
   "metadata": {},
   "source": [
    "### PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a323c58",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/psi/gaussian'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    int_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PSI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    x_logits_list = []\n",
    "    y_labels_list = []\n",
    "\n",
    "    for x_batch, y_batch in ds_train.batch(256):\n",
    "        logits = int_model(x_batch)\n",
    "        labels = tf.argmax(y_batch, axis=1)\n",
    "        x_logits_list.append(logits)\n",
    "        y_labels_list.append(labels)\n",
    "\n",
    "    x = tf.concat(x_logits_list, axis=0).numpy()\n",
    "    y = tf.concat(y_labels_list, axis=0).numpy()\n",
    "    \n",
    "    print(f'Training PSI model (gaussian)...')\n",
    "    psi_data = psi_gaussian_train(x, y, n_projs=500)\n",
    "    np.save(f'{exp_name}/gaussian_output_model_500_projs.npy', psi_data)\n",
    "\n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PSI for all validation and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "\n",
    "    psi_data = np.load(f'{exp_name}/gaussian_output_model_500_projs.npy', allow_pickle=True).item()\n",
    "\n",
    "    print(f'Computing PSI for all validation samples...')\n",
    "    x_logits_list = []\n",
    "\n",
    "    for x_batch, y_batch in ds_val.batch(256):\n",
    "        logits = int_model(x_batch)\n",
    "        x_logits_list.append(logits)\n",
    "    \n",
    "    x = tf.concat(x_logits_list, axis=0).numpy()\n",
    "    psi_class, pmi_arr = psi_gaussian_val_class(x, psi_data)\n",
    "    np.save(f'{exp_name}/psi_output_class_500_projs_val.npy', np.array(psi_class))\n",
    "\n",
    "    print(f'Computing PSI for all test samples...')\n",
    "    x_logits_list = []\n",
    "\n",
    "    for x_batch, y_batch in ds_test.batch(256):\n",
    "        logits = int_model(x_batch)\n",
    "        x_logits_list.append(logits)\n",
    "    \n",
    "    x = tf.concat(x_logits_list, axis=0).numpy()\n",
    "    psi_class, pmi_arr = psi_gaussian_val_class(x, psi_data)\n",
    "    np.save(f'{exp_name}/psi_output_class_500_projs_test.npy', np.array(psi_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5e090",
   "metadata": {},
   "source": [
    "### PVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5911ab",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_runs = list(range(10))\n",
    "while any(random_runs[i] == i for i in range(10)):\n",
    "    np.random.shuffle(random_runs)\n",
    "    \n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{random_runs[run]+1}/saved_models/trained_weights.h5')\n",
    "    pvi_model.save_weights(f'{exp_name}/pvi_model_weights.h5')\n",
    "    \n",
    "    untrained_model = create_model()\n",
    "    train_pvi_null_model(ds_train, untrained_model, epochs=10, save_path=f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'{exp_name}/pvi_model_weights.h5')\n",
    "    null_model = create_model()\n",
    "    null_model.load_weights(f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "    opt_temp_pvi = utils.temp_scaling_nll(pvi_model.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "    ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "    opt_temp_null = utils.temp_scaling_nll(null_model.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "\n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_val.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_test.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403b543",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "pvi_runs = [3 if i == 0 else 0 for i in range(10)]\n",
    "    \n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{pvi_runs[run]+1}/saved_models/trained_weights.h5')\n",
    "    pvi_model.save_weights(f'{exp_name}/pvi_model_best_weights.h5')\n",
    "    \n",
    "#     untrained_model = create_model()\n",
    "#     train_pvi_null_model(ds_train, untrained_model, epochs=10, save_path=f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'{exp_name}/pvi_model_best_weights.h5')\n",
    "    null_model = create_model()\n",
    "    null_model.load_weights(f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "    opt_temp_pvi = temp_scaling.temp_scaling_nll(pvi_model.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "    ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "    opt_temp_null = temp_scaling.temp_scaling_nll(null_model.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "\n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_val.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_best_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_test.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_best_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823e3720",
   "metadata": {},
   "source": [
    "### Ensemble PVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c3723f9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/ensemble_no_training_training_from_scratch'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model_1 = create_model()\n",
    "    pvi_model_1.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    null_model_1 = create_model()\n",
    "    null_model_1.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_null_model_weights.h5')\n",
    "    pvi_model_2 = create_model()\n",
    "    pvi_model_2.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_model_weights.h5')\n",
    "    null_model_2 = create_model()\n",
    "    null_model_2.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_null_model_weights.h5')\n",
    "    \n",
    "#     true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "#     opt_temp_pvi_1 = utils.temp_scaling_nll(pvi_model_1.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "#     opt_temp_pvi_2 = utils.temp_scaling_nll(pvi_model_2.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "#     ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "#     opt_temp_null = utils.temp_scaling_nll(null_model_1.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = []\n",
    "    for (x_batch, y_batch) in ds_val.batch(256):\n",
    "        pvi = neural_pvi_ensemble_class([x_batch, x_batch], [pvi_model_1, pvi_model_2], [null_model_1, null_model_2])\n",
    "        pvi_class += np.array(pvi).tolist()\n",
    "    np.save(f'{exp_name}/pvi_class_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = []\n",
    "    for (x_batch, y_batch) in ds_test.batch(256):\n",
    "        pvi = neural_pvi_ensemble_class([x_batch, x_batch], [pvi_model_1, pvi_model_2], [null_model_1, null_model_2])\n",
    "        pvi_class += np.array(pvi).tolist()\n",
    "    np.save(f'{exp_name}/pvi_class_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbfa7c9a",
   "metadata": {},
   "source": [
    "### Temp Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c0e91",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "#     if not os.path.exists(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'):\n",
    "#         print(\"Making directory\", f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration')\n",
    "#         os.makedirs(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration')                                  \n",
    "  \n",
    "    \n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = model.predict(ds_val.batch(512), verbose=0)\n",
    "    \n",
    "#     opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)\n",
    "#     np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)\n",
    "    np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_nll.npy', opt_temp)\n",
    "\n",
    "#     opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)\n",
    "#     np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8aed08",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/psi/gaussian'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/psi_output_class_500_projs_val.npy')\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                                 \n",
    "    np.save(f'{exp_name}/psi_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                            \n",
    "    np.save(f'{exp_name}/psi_opt_temp_nll.npy', opt_temp)\n",
    "    \n",
    "#     opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                            \n",
    "#     np.save(f'{exp_name}/psi_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11382f69",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pvi_class_val.npy')\n",
    "    \n",
    "#     opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                                 \n",
    "#     np.save(f'{exp_name}/pvi_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                                          \n",
    "    np.save(f'{exp_name}/pvi_opt_temp_nll.npy', opt_temp)\n",
    "\n",
    "#     opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                                          \n",
    "#     np.save(f'{exp_name}/pvi_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e973c54",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pvi_class_best_val.npy')\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                                 \n",
    "    np.save(f'{exp_name}/pvi_best_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                                          \n",
    "    np.save(f'{exp_name}/pvi_best_opt_temp_nll.npy', opt_temp)\n",
    "\n",
    "#     opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                                          \n",
    "#     np.save(f'{exp_name}/pvi_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58365931",
   "metadata": {},
   "source": [
    "### Failure Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862d8e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_scores(conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name):\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'\n",
    "    metric = conf_method.split('_')[-1] if 'temp_scaling' in conf_method else None\n",
    "    method_key = conf_method.replace(f'_temp_scaling_{metric}', '') if metric else conf_method\n",
    "\n",
    "    if method_key == 'softmax':\n",
    "        if metric:\n",
    "            opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "            return methods.max_softmax_prob(model, ds_test, opt_temp)\n",
    "        else:\n",
    "            return methods.max_softmax_prob(model, ds_test)\n",
    "\n",
    "    elif method_key in ['pmi', 'psi', 'pvi', 'pvi_best']:\n",
    "        if method_key == 'pmi':\n",
    "            exp_path = f'{base_path}/pmi/separable_variational_f_js'\n",
    "            class_file = 'pmi_output_class_test.npy'\n",
    "        elif method_key == 'psi':\n",
    "            exp_path = f'{base_path}/psi/gaussian'\n",
    "            class_file = 'psi_output_class_500_projs_test.npy'\n",
    "        elif method_key == 'pvi':\n",
    "            exp_path = f'{base_path}/pvi/training_from_scratch'\n",
    "            class_file = 'pvi_class_test.npy'\n",
    "        elif method_key == 'pvi_best':\n",
    "            exp_path = f'{base_path}/pvi/training_from_scratch'\n",
    "            class_file = 'pvi_class_best_test.npy'\n",
    "\n",
    "        opt_temp = np.load(f'{exp_path}/{method_key}_opt_temp_{metric}.npy')\n",
    "        scores_class = np.load(f'{exp_path}/{class_file}')\n",
    "        scores_class = np.array([utils.softmax(x / opt_temp) for x in scores_class])\n",
    "        return np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "\n",
    "    elif method_key == 'softmax_margin':\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        return methods.softmax_margin(model, ds_test, opt_temp)\n",
    "\n",
    "    elif method_key == 'max_logits':\n",
    "        return methods.max_logits(model, ds_test)\n",
    "\n",
    "    elif method_key == 'logits_margin':\n",
    "        return methods.logits_margin(model, ds_test)\n",
    "\n",
    "    elif method_key == 'negative_entropy':\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        return methods.negative_entropy(model, ds_test, opt_temp)\n",
    "\n",
    "    elif method_key == 'negative_gini':\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        return methods.negative_gini(model, ds_test, opt_temp)\n",
    "\n",
    "    elif method_key == 'isotonic_regression':\n",
    "        return methods.isotonic_reg(model, ds_val, ds_test, true_y_val)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown confidence method: {conf_method}\")\n",
    "\n",
    "\n",
    "def evaluate_failure_pred(ds_test, true_y_test, conf_method, n_runs=10):\n",
    "    results = {\n",
    "        \"auroc\": [],\n",
    "        \"fpr_at_95tpr\": [],\n",
    "        \"auprc_success\": [],\n",
    "        \"auprc_error\": [],\n",
    "        \"aurc\": [],\n",
    "        \"eaurc\": [],\n",
    "        \"naurc\": []\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        scores_test = get_confidence_scores(conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name)\n",
    "\n",
    "#         results[\"auroc\"].append(metrics.compute_auroc(scores_test, pred_y_test, true_y_test))\n",
    "#         results[\"auprc_success\"].append(metrics.compute_auprc_success(scores_test, pred_y_test, true_y_test))\n",
    "#         results[\"auprc_error\"].append(metrics.compute_auprc_error(scores_test, pred_y_test, true_y_test))\n",
    "#         results[\"fpr_at_95tpr\"].append(metrics.compute_fpr_at_95tpr(scores_test, pred_y_test, true_y_test))\n",
    "#         results[\"aurc\"].append(metrics.compute_aurc(scores_test, pred_y_test, true_y_test))\n",
    "#         results[\"eaurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"naurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0a970",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods_list = ['softmax_temp_scaling_aurc','psi_temp_scaling_aurc','pvi_temp_scaling_aurc',\n",
    "                'softmax_margin_temp_scaling_aurc', 'max_logits', 'logits_margin', 'negative_entropy_temp_scaling_aurc',\n",
    "                'negative_gini_temp_scaling_aurc']\n",
    "for method in methods_list:\n",
    "    print(f'Method: {method}')\n",
    "    results = evaluate_failure_pred(ds_test, true_y_test, conf_method=f'{method}', n_runs=10)\n",
    "#     print(f\"AUROC           : {utils.format_ci(results['auroc'], scale=100)}\")\n",
    "#     print(f\"AUPRC (success) : {utils.format_ci(results['auprc_success'], scale=100)}\")\n",
    "#     print(f\"AUPRC (error)   : {utils.format_ci(results['auprc_error'], scale=100)}\")\n",
    "#     print(f\"FPR at 95% TPR  : {utils.format_ci(results['fpr_at_95tpr'], scale=100)}\")\n",
    "#     print(f\"AURC            : {utils.format_ci(results['aurc'], scale=1000)}\")\n",
    "#     print(f\"EAURC           : {utils.format_ci(results['eaurc'], scale=1000)}\")\n",
    "    print(f\"NAURC           : {utils.format_ci(results['naurc'], scale=1000)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f78b29",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a68971f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_calibration(conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name):\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'\n",
    "\n",
    "    def softmax_scaled(scores, temp=1.0):\n",
    "        return np.array([utils.softmax(x / temp) for x in scores])\n",
    "\n",
    "    if conf_method == 'softmax':\n",
    "        scores_class = methods.softmax_prob(model, ds_test)\n",
    "        scores_test = methods.max_softmax_prob(model, ds_test)\n",
    "        return scores_class, scores_test\n",
    "\n",
    "    if conf_method.startswith('softmax_temp_scaling'):\n",
    "        metric = conf_method.split('_')[-1]\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        scores_class = methods.softmax_prob(model, ds_test, opt_temp)\n",
    "        scores_test = methods.max_softmax_prob(model, ds_test, opt_temp)\n",
    "        return scores_class, scores_test\n",
    "\n",
    "    if conf_method in ['pmi', 'psi', 'pvi', 'pvi_best']:\n",
    "        method = conf_method\n",
    "        metric = None\n",
    "        temp = 1.0\n",
    "    elif conf_method.startswith(('pmi_temp_scaling', 'psi_temp_scaling', 'pvi_temp_scaling', 'pvi_best_temp_scaling')):\n",
    "        parts = conf_method.split('_')\n",
    "        method = '_'.join(parts[:2]) if 'best' in parts else parts[0]\n",
    "        metric = parts[-1]\n",
    "        method_dir = {\n",
    "            'pmi': 'pmi/separable_variational_f_js',\n",
    "            'psi': 'psi/gaussian',\n",
    "            'pvi': 'pvi/training_from_scratch',\n",
    "            'pvi_best': 'pvi/training_from_scratch'\n",
    "        }[method]\n",
    "        temp = float(np.load(f'{base_path}/{method_dir}/{method}_opt_temp_{metric}.npy'))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown confidence method: {conf_method}\")\n",
    "\n",
    "    method_paths = {\n",
    "        'pmi': (f'{base_path}/pmi/separable_variational_f_js', 'pmi_output_class_test.npy'),\n",
    "        'psi': (f'{base_path}/psi/gaussian', 'psi_output_class_500_projs_test.npy'),\n",
    "        'pvi': (f'{base_path}/pvi/training_from_scratch', 'pvi_class_test.npy'),\n",
    "        'pvi_best': (f'{base_path}/pvi/training_from_scratch', 'pvi_class_best_test.npy'),\n",
    "    }\n",
    "\n",
    "    method_path, class_file = method_paths[method]\n",
    "    scores_class = np.load(f'{method_path}/{class_file}')\n",
    "    scores_class = softmax_scaled(scores_class, temp)\n",
    "    scores_test = np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "    return scores_class, scores_test\n",
    "\n",
    "def evaluate_calibration(ds_test, true_y_test, conf_method, n_runs=10):\n",
    "    results = {\n",
    "        \"ece\": [],\n",
    "        \"cc_ece\": [],\n",
    "        \"mce\": [],\n",
    "        \"ace\": [],\n",
    "        \"sce\": [],\n",
    "        \"ada_ece\": [],\n",
    "        \"ada_sce\": [],\n",
    "        \"cc_ada_ece\": [],\n",
    "        \"cc_ada_sce\": [],\n",
    "        \"cc_ada_sce_rms\": [],\n",
    "        \"cw_ece\": [],\n",
    "        \"cw_sce\": [],\n",
    "        \"cw_ada_ece\": [],\n",
    "        \"cw_ada_sce\": [],\n",
    "        \"cw_ada_ece_rms\": [],\n",
    "        \"cw_ada_sce_rms\": [],\n",
    "        \"nll\": [],\n",
    "        \"bs\": [],\n",
    "        \"sharpness\": [],\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        scores_class, scores_test = get_scores_for_calibration(\n",
    "            conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name\n",
    "        )\n",
    "\n",
    "#         results[\"ece\"].append(metrics.compute_ece(scores_test, pred_y_test, true_y_test, 15))\n",
    "#         results[\"cc_ece\"].append(metrics.compute_cc_ece(scores_test, pred_y_test, true_y_test, 15))\n",
    "#         results[\"mce\"].append(metrics.compute_mce(scores_test, pred_y_test, true_y_test, 15))\n",
    "#         results[\"ace\"].append(metrics.compute_ace(scores_test, pred_y_test, true_y_test, 15))\n",
    "#         results[\"sce\"].append(metrics.compute_sce(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"ada_ece\"].append(metrics.compute_adaece(scores_test, pred_y_test, true_y_test, 15))\n",
    "#         results[\"ada_sce\"].append(metrics.compute_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cc_ada_ece\"].append(metrics.compute_cc_adaece(scores_test, pred_y_test, true_y_test, 15))\n",
    "#         results[\"cc_ada_sce\"].append(metrics.compute_cc_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cc_ada_sce_rms\"].append(metrics.compute_cc_adasce_rms(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cw_ece\"].append(metrics.compute_cw_ece(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cw_sce\"].append(metrics.compute_cw_sce(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cw_ada_ece\"].append(metrics.compute_cw_adaece(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cw_ada_sce\"].append(metrics.compute_cw_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cw_ada_ece_rms\"].append(metrics.compute_cw_adaece_rms(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"cw_ada_sce_rms\"].append(metrics.compute_cw_adaece_rms(scores_class, true_y_test, num_classes, 15))\n",
    "#         results[\"nll\"].append(metrics.compute_nll(scores_class, true_y_test, num_classes))\n",
    "#         results[\"bs\"].append(metrics.compute_brier_score(scores_class, true_y_test, num_classes))\n",
    "#         results[\"sharpness\"].append(metrics.compute_sharpness(scores_class))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9442857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: softmax\n",
      "CC-Ada-SCE-RMS: 2.98 (0.09)\n",
      "Method: psi\n",
      "CC-Ada-SCE-RMS: 3.97 (0.14)\n",
      "Method: pvi\n",
      "CC-Ada-SCE-RMS: 3.75 (0.05)\n",
      "Method: pvi_best\n",
      "CC-Ada-SCE-RMS: 3.66 (0.01)\n",
      "Method: softmax_temp_scaling_nll\n",
      "CC-Ada-SCE-RMS: 3.75 (0.05)\n",
      "Method: psi_temp_scaling_nll\n",
      "CC-Ada-SCE-RMS: 3.88 (0.04)\n",
      "Method: pvi_temp_scaling_nll\n",
      "CC-Ada-SCE-RMS: 3.75 (0.05)\n",
      "Method: pvi_best_temp_scaling_nll\n",
      "CC-Ada-SCE-RMS: 3.66 (0.01)\n"
     ]
    }
   ],
   "source": [
    "methods_list = ['softmax','psi','pvi','pvi_best','softmax_temp_scaling_nll','psi_temp_scaling_nll','pvi_temp_scaling_nll','pvi_best_temp_scaling_nll']\n",
    "for method in methods_list:\n",
    "    print(f'Method: {method}')\n",
    "    results = evaluate_calibration(ds_test, true_y_test, conf_method=f'{method}', n_runs=10)\n",
    "#     print(f\"ECE:            {utils.format_ci(results['ece'], scale=100)}\")\n",
    "#     print(f\"CC-ECE:         {utils.format_ci(results['cc_ece'], scale=100)}\")\n",
    "#     print(f\"MCE:            {utils.format_ci(results['mce'], scale=100)}\")\n",
    "#     print(f\"ACE:            {utils.format_ci(results['ace'], scale=100)}\")\n",
    "#     print(f\"SCE:            {utils.format_ci(results['sce'], scale=100)}\")\n",
    "#     print(f\"Ada-ECE:        {utils.format_ci(results['ada_ece'], scale=100)}\")\n",
    "#     print(f\"Ada-SCE:        {utils.format_ci(results['ada_sce'], scale=100)}\")\n",
    "#     print(f\"CC-Ada-ECE:     {utils.format_ci(results['cc_ada_ece'], scale=100)}\")\n",
    "#     print(f\"CC-Ada-SCE:     {utils.format_ci(results['cc_ada_sce'], scale=100)}\")\n",
    "    print(f\"CC-Ada-SCE-RMS: {utils.format_ci(results['cc_ada_sce_rms'], scale=100)}\")\n",
    "#     print(f\"CW-ECE:         {utils.format_ci(results['cw_ece'], scale=100)}\")\n",
    "#     print(f\"CW-SCE:         {utils.format_ci(results['cw_sce'], scale=100)}\")\n",
    "#     print(f\"CW-Ada-ECE:     {utils.format_ci(results['cw_ada_ece'], scale=100)}\")\n",
    "#     print(f\"CW-Ada-SCE:     {utils.format_ci(results['cw_ada_sce'], scale=100)}\")\n",
    "#     print(f\"CW-Ada-ECE-RMS: {utils.format_ci(results['cw_ada_ece_rms'], scale=100)}\")\n",
    "#     print(f\"CW-Ada-SCE-RMS: {utils.format_ci(results['cw_ada_sce_rms'], scale=100)}\")\n",
    "#     print(f\"NLL:            {utils.format_ci(results['nll'], scale=100)}\")\n",
    "#     print(f\"Brier Score:    {utils.format_ci(results['bs'], scale=100)}\")\n",
    "#     print(f\"Sharpness:      {utils.format_ci(results['sharpness'], scale=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f49ecaa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
