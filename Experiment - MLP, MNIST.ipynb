{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7389f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 10:13:49.193148: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9373] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-06-05 10:13:49.193226: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-06-05 10:13:49.194566: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1534] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-06-05 10:13:49.201809: I tensorflow/core/platform/cpu_feature_guard.cc:183] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE3 SSE4.1 SSE4.2 AVX, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import AdamW\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from src.pmi_estimators import train_critic_model, neural_pmi\n",
    "from src.psi_estimators import psi_gaussian_train, psi_gaussian_val_class\n",
    "from src.pvi_estimators import train_pvi_null_model, neural_pvi_class, neural_pvi_ensemble_class\n",
    "import src.utils as utils\n",
    "import src.metrics as metrics\n",
    "import src.methods as methods\n",
    "import src.temp_scaling as temp_scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db1da5f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 10:13:52.469347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1926] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 78835 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-80GB, pci bus id: 0000:47:00.0, compute capability: 8.0\n"
     ]
    }
   ],
   "source": [
    "model_name = 'mlp'\n",
    "dataset_name = 'mnist'\n",
    "\n",
    "(ds_train, ds_val, ds_test), ds_info = tfds.load(\n",
    "    'mnist',\n",
    "    split=['train[:85%]', 'train[85%:]', 'test'],\n",
    "    data_dir = '../tensorflow_datasets/',\n",
    "    shuffle_files=False,\n",
    "    as_supervised=True,\n",
    "    with_info=True\n",
    ")\n",
    "\n",
    "num_classes = 10\n",
    "def preprocess(image, label):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(label, depth=num_classes)\n",
    "    return image, label\n",
    "\n",
    "ds_train = ds_train.map(preprocess)\n",
    "ds_val = ds_val.map(preprocess)\n",
    "ds_test = ds_test.map(preprocess)\n",
    "\n",
    "# batch_size = 128\n",
    "# ds_train = ds_train.shuffle(1000).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "# ds_val = ds_val.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "# ds_test = ds_test.batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "true_y_train = np.argmax([y for x,y in ds_train], axis=1)\n",
    "true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "true_y_test = np.argmax([y for x,y in ds_test], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d91fd338",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(Flatten(input_shape=(28,28,1)))\n",
    "    for _ in range(3):\n",
    "        model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(10, activation='linear'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4cf32ab",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf2902c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-05 08:44:08.732839: I external/local_xla/xla/service/service.cc:168] XLA service 0x7f1dcd2ed4d0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-06-05 08:44:08.732884: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA A100-SXM4-80GB, Compute Capability 8.0\n",
      "2025-06-05 08:44:08.738574: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-05 08:44:08.777874: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:467] Loaded cuDNN version 90100\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1749113048.873410   10741 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399/399 [==============================] - 3s 4ms/step - loss: 0.5109 - accuracy: 0.8713 - val_loss: 0.2283 - val_accuracy: 0.9373 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1837 - accuracy: 0.9467 - val_loss: 0.1682 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1328 - accuracy: 0.9612 - val_loss: 0.1324 - val_accuracy: 0.9637 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1021 - accuracy: 0.9705 - val_loss: 0.1144 - val_accuracy: 0.9688 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9766 - val_loss: 0.1061 - val_accuracy: 0.9691 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0670 - accuracy: 0.9807 - val_loss: 0.0959 - val_accuracy: 0.9724 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0557 - accuracy: 0.9840 - val_loss: 0.0896 - val_accuracy: 0.9740 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0449 - accuracy: 0.9874 - val_loss: 0.0875 - val_accuracy: 0.9746 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0370 - accuracy: 0.9902 - val_loss: 0.0855 - val_accuracy: 0.9750 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0296 - accuracy: 0.9922 - val_loss: 0.0887 - val_accuracy: 0.9747 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9937 - val_loss: 0.0858 - val_accuracy: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0193 - accuracy: 0.9955 - val_loss: 0.0820 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0152 - accuracy: 0.9966 - val_loss: 0.0814 - val_accuracy: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0125 - accuracy: 0.9972 - val_loss: 0.0842 - val_accuracy: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9981 - val_loss: 0.0832 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0089 - accuracy: 0.9982 - val_loss: 0.0826 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0075 - accuracy: 0.9985 - val_loss: 0.0859 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9995 - val_loss: 0.0988 - val_accuracy: 0.9767 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9996 - val_loss: 0.0897 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0927 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9981 - val_loss: 0.0998 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0052 - accuracy: 0.9987 - val_loss: 0.0912 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9996 - val_loss: 0.0967 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0953 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 0.9999 - val_loss: 0.0936 - val_accuracy: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.2165e-04 - accuracy: 1.0000 - val_loss: 0.0982 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.1824e-04 - accuracy: 1.0000 - val_loss: 0.1002 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.3457e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.7900e-04 - accuracy: 1.0000 - val_loss: 0.1045 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "382/399 [===========================>..] - ETA: 0s - loss: 2.3468e-04 - accuracy: 1.0000\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.3288e-04 - accuracy: 1.0000 - val_loss: 0.1077 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.8698e-04 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9799 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.6379e-04 - accuracy: 1.0000 - val_loss: 0.1105 - val_accuracy: 0.9797 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.4648e-04 - accuracy: 1.0000 - val_loss: 0.1125 - val_accuracy: 0.9799 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.3066e-04 - accuracy: 1.0000 - val_loss: 0.1136 - val_accuracy: 0.9793 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "382/399 [===========================>..] - ETA: 0s - loss: 1.1772e-04 - accuracy: 1.0000\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "399/399 [==============================] - 2s 4ms/step - loss: 1.1680e-04 - accuracy: 1.0000 - val_loss: 0.1145 - val_accuracy: 0.9799 - lr: 5.0000e-05\n",
      "Epoch 35: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_1/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_2\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 4ms/step - loss: 0.5163 - accuracy: 0.8666 - val_loss: 0.2382 - val_accuracy: 0.9338 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1825 - accuracy: 0.9471 - val_loss: 0.1683 - val_accuracy: 0.9547 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1309 - accuracy: 0.9615 - val_loss: 0.1384 - val_accuracy: 0.9612 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1001 - accuracy: 0.9708 - val_loss: 0.1142 - val_accuracy: 0.9673 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0804 - accuracy: 0.9769 - val_loss: 0.1066 - val_accuracy: 0.9688 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0639 - accuracy: 0.9817 - val_loss: 0.0996 - val_accuracy: 0.9711 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0526 - accuracy: 0.9853 - val_loss: 0.0889 - val_accuracy: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0427 - accuracy: 0.9881 - val_loss: 0.0854 - val_accuracy: 0.9752 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0342 - accuracy: 0.9908 - val_loss: 0.0856 - val_accuracy: 0.9764 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0293 - accuracy: 0.9925 - val_loss: 0.0835 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0243 - accuracy: 0.9935 - val_loss: 0.0904 - val_accuracy: 0.9737 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0179 - accuracy: 0.9960 - val_loss: 0.0839 - val_accuracy: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0146 - accuracy: 0.9970 - val_loss: 0.0867 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0124 - accuracy: 0.9974 - val_loss: 0.0818 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0864 - val_accuracy: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9989 - val_loss: 0.0872 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0064 - accuracy: 0.9989 - val_loss: 0.0857 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9994 - val_loss: 0.0926 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "392/399 [============================>.] - ETA: 0s - loss: 0.0049 - accuracy: 0.9990\n",
      "Epoch 19: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9991 - val_loss: 0.0909 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0021 - accuracy: 0.9999 - val_loss: 0.0891 - val_accuracy: 0.9804 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0907 - val_accuracy: 0.9803 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0918 - val_accuracy: 0.9806 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 9.8102e-04 - accuracy: 1.0000 - val_loss: 0.0948 - val_accuracy: 0.9803 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 8.7417e-04 - accuracy: 1.0000 - val_loss: 0.0946 - val_accuracy: 0.9804 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.6534e-04 - accuracy: 1.0000 - val_loss: 0.0972 - val_accuracy: 0.9809 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9998 - val_loss: 0.1019 - val_accuracy: 0.9796 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0013 - accuracy: 0.9999 - val_loss: 0.0991 - val_accuracy: 0.9814 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.5324e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9810 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.0807e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9806 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.3682e-04 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9811 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.2513e-04 - accuracy: 1.0000 - val_loss: 0.1073 - val_accuracy: 0.9807 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - ETA: 0s - loss: 2.8728e-04 - accuracy: 1.0000\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.8728e-04 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9813 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.1129e-04 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9811 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.8850e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9810 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.6788e-04 - accuracy: 1.0000 - val_loss: 0.1110 - val_accuracy: 0.9810 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.5129e-04 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9812 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "384/399 [===========================>..] - ETA: 0s - loss: 1.3696e-04 - accuracy: 1.0000\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.3679e-04 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9810 - lr: 2.5000e-05\n",
      "Epoch 37: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_2/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_3\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 3ms/step - loss: 0.5073 - accuracy: 0.8703 - val_loss: 0.2277 - val_accuracy: 0.9359 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1827 - accuracy: 0.9471 - val_loss: 0.1648 - val_accuracy: 0.9549 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1316 - accuracy: 0.9612 - val_loss: 0.1335 - val_accuracy: 0.9624 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1010 - accuracy: 0.9704 - val_loss: 0.1154 - val_accuracy: 0.9664 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9770 - val_loss: 0.1041 - val_accuracy: 0.9703 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0646 - accuracy: 0.9822 - val_loss: 0.0941 - val_accuracy: 0.9726 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9855 - val_loss: 0.0949 - val_accuracy: 0.9712 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0422 - accuracy: 0.9887 - val_loss: 0.0843 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0348 - accuracy: 0.9908 - val_loss: 0.0873 - val_accuracy: 0.9751 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0280 - accuracy: 0.9929 - val_loss: 0.0845 - val_accuracy: 0.9770 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9944 - val_loss: 0.0832 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0182 - accuracy: 0.9955 - val_loss: 0.0831 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0141 - accuracy: 0.9971 - val_loss: 0.0838 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0123 - accuracy: 0.9976 - val_loss: 0.0887 - val_accuracy: 0.9761 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9984 - val_loss: 0.0843 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0074 - accuracy: 0.9988 - val_loss: 0.0894 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0888 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9995 - val_loss: 0.0948 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0031 - accuracy: 0.9997 - val_loss: 0.0945 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0068 - accuracy: 0.9983 - val_loss: 0.0964 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9990 - val_loss: 0.0973 - val_accuracy: 0.9771 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0033 - accuracy: 0.9994 - val_loss: 0.0970 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9803 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.5672e-04 - accuracy: 1.0000 - val_loss: 0.1016 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.2827e-04 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9800 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0090 - accuracy: 0.9970 - val_loss: 0.1195 - val_accuracy: 0.9746 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.1003 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "381/399 [===========================>..] - ETA: 0s - loss: 0.0019 - accuracy: 0.9997\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9997 - val_loss: 0.1048 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.5235e-04 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9799 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.1601e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9804 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.5382e-04 - accuracy: 1.0000 - val_loss: 0.1059 - val_accuracy: 0.9802 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.0459e-04 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9802 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.6362e-04 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9801 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.3132e-04 - accuracy: 1.0000 - val_loss: 0.1120 - val_accuracy: 0.9803 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "395/399 [============================>.] - ETA: 0s - loss: 2.0099e-04 - accuracy: 1.0000\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.0081e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9804 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.7646e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9804 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.6162e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9804 - lr: 2.5000e-05\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.4847e-04 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9804 - lr: 2.5000e-05\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.3685e-04 - accuracy: 1.0000 - val_loss: 0.1162 - val_accuracy: 0.9807 - lr: 2.5000e-05\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.2466e-04 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9804 - lr: 2.5000e-05\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.1249e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9801 - lr: 2.5000e-05\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.0250e-04 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9801 - lr: 2.5000e-05\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 9.1848e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9798 - lr: 2.5000e-05\n",
      "Epoch 44/100\n",
      "378/399 [===========================>..] - ETA: 0s - loss: 8.0770e-05 - accuracy: 1.0000\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.9708e-05 - accuracy: 1.0000 - val_loss: 0.1237 - val_accuracy: 0.9800 - lr: 2.5000e-05\n",
      "Epoch 45/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.1120e-05 - accuracy: 1.0000 - val_loss: 0.1234 - val_accuracy: 0.9800 - lr: 1.2500e-05\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.5224e-05 - accuracy: 1.0000 - val_loss: 0.1241 - val_accuracy: 0.9800 - lr: 1.2500e-05\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.0442e-05 - accuracy: 1.0000 - val_loss: 0.1255 - val_accuracy: 0.9800 - lr: 1.2500e-05\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.6138e-05 - accuracy: 1.0000 - val_loss: 0.1265 - val_accuracy: 0.9800 - lr: 1.2500e-05\n",
      "Epoch 49/100\n",
      "394/399 [============================>.] - ETA: 0s - loss: 5.0905e-05 - accuracy: 1.0000\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Restoring model weights from the end of the best epoch: 39.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.0883e-05 - accuracy: 1.0000 - val_loss: 0.1271 - val_accuracy: 0.9800 - lr: 1.2500e-05\n",
      "Epoch 49: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_3/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_4\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 3ms/step - loss: 0.5060 - accuracy: 0.8711 - val_loss: 0.2300 - val_accuracy: 0.9362 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1814 - accuracy: 0.9469 - val_loss: 0.1619 - val_accuracy: 0.9557 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9620 - val_loss: 0.1341 - val_accuracy: 0.9624 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1014 - accuracy: 0.9703 - val_loss: 0.1181 - val_accuracy: 0.9664 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0806 - accuracy: 0.9768 - val_loss: 0.1029 - val_accuracy: 0.9707 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0648 - accuracy: 0.9814 - val_loss: 0.0975 - val_accuracy: 0.9717 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0527 - accuracy: 0.9855 - val_loss: 0.0878 - val_accuracy: 0.9749 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0438 - accuracy: 0.9877 - val_loss: 0.0871 - val_accuracy: 0.9746 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0353 - accuracy: 0.9906 - val_loss: 0.0825 - val_accuracy: 0.9766 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0292 - accuracy: 0.9922 - val_loss: 0.0782 - val_accuracy: 0.9778 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0238 - accuracy: 0.9937 - val_loss: 0.0776 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0185 - accuracy: 0.9960 - val_loss: 0.0824 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0158 - accuracy: 0.9961 - val_loss: 0.0853 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.0811 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0083 - accuracy: 0.9987 - val_loss: 0.0819 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0079 - accuracy: 0.9984 - val_loss: 0.0861 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9993 - val_loss: 0.0906 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9988 - val_loss: 0.0912 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0032 - accuracy: 0.9997 - val_loss: 0.0961 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0070 - accuracy: 0.9983 - val_loss: 0.1016 - val_accuracy: 0.9763 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9989 - val_loss: 0.0951 - val_accuracy: 0.9793 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0018 - accuracy: 0.9999 - val_loss: 0.0975 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.0997 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.5110e-04 - accuracy: 1.0000 - val_loss: 0.1025 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.3810e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.4420e-04 - accuracy: 1.0000 - val_loss: 0.1068 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.0225e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0134 - accuracy: 0.9960 - val_loss: 0.1016 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0022 - accuracy: 0.9996 - val_loss: 0.1051 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "396/399 [============================>.] - ETA: 0s - loss: 7.3257e-04 - accuracy: 1.0000\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.3000e-04 - accuracy: 1.0000 - val_loss: 0.1033 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.6163e-04 - accuracy: 1.0000 - val_loss: 0.1024 - val_accuracy: 0.9793 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.9860e-04 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9793 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.5667e-04 - accuracy: 1.0000 - val_loss: 0.1051 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.2630e-04 - accuracy: 1.0000 - val_loss: 0.1063 - val_accuracy: 0.9796 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "395/399 [============================>.] - ETA: 0s - loss: 1.9822e-04 - accuracy: 1.0000\n",
      "Epoch 35: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Restoring model weights from the end of the best epoch: 25.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.9878e-04 - accuracy: 1.0000 - val_loss: 0.1079 - val_accuracy: 0.9794 - lr: 5.0000e-05\n",
      "Epoch 35: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_4/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_5\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 4ms/step - loss: 0.5024 - accuracy: 0.8728 - val_loss: 0.2291 - val_accuracy: 0.9397 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1835 - accuracy: 0.9466 - val_loss: 0.1647 - val_accuracy: 0.9563 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1303 - accuracy: 0.9623 - val_loss: 0.1326 - val_accuracy: 0.9644 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1006 - accuracy: 0.9716 - val_loss: 0.1200 - val_accuracy: 0.9658 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0805 - accuracy: 0.9769 - val_loss: 0.1033 - val_accuracy: 0.9710 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0643 - accuracy: 0.9814 - val_loss: 0.1013 - val_accuracy: 0.9692 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0523 - accuracy: 0.9856 - val_loss: 0.0908 - val_accuracy: 0.9739 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0429 - accuracy: 0.9883 - val_loss: 0.0839 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0347 - accuracy: 0.9911 - val_loss: 0.0846 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0284 - accuracy: 0.9925 - val_loss: 0.0887 - val_accuracy: 0.9754 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0227 - accuracy: 0.9945 - val_loss: 0.0804 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0178 - accuracy: 0.9961 - val_loss: 0.0826 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0144 - accuracy: 0.9970 - val_loss: 0.0798 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9978 - val_loss: 0.0839 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0929 - val_accuracy: 0.9774 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0072 - accuracy: 0.9988 - val_loss: 0.0931 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0892 - val_accuracy: 0.9792 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9989 - val_loss: 0.0898 - val_accuracy: 0.9793 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0036 - accuracy: 0.9996 - val_loss: 0.0865 - val_accuracy: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0927 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9996 - val_loss: 0.0924 - val_accuracy: 0.9808 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.0960 - val_accuracy: 0.9801 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 9.4763e-04 - accuracy: 1.0000 - val_loss: 0.0967 - val_accuracy: 0.9807 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.0758e-04 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9811 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.9673e-04 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9814 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.3092e-04 - accuracy: 1.0000 - val_loss: 0.1030 - val_accuracy: 0.9812 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.3075e-04 - accuracy: 1.0000 - val_loss: 0.1038 - val_accuracy: 0.9810 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.7444e-04 - accuracy: 1.0000 - val_loss: 0.1067 - val_accuracy: 0.9813 - lr: 1.0000e-04\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.2378e-04 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9811 - lr: 1.0000e-04\n",
      "Epoch 30/100\n",
      "386/399 [============================>.] - ETA: 0s - loss: 1.8441e-04 - accuracy: 1.0000\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.8372e-04 - accuracy: 1.0000 - val_loss: 0.1118 - val_accuracy: 0.9802 - lr: 1.0000e-04\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.4903e-04 - accuracy: 1.0000 - val_loss: 0.1133 - val_accuracy: 0.9809 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.2738e-04 - accuracy: 1.0000 - val_loss: 0.1144 - val_accuracy: 0.9816 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.1214e-04 - accuracy: 1.0000 - val_loss: 0.1156 - val_accuracy: 0.9811 - lr: 5.0000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.0434e-04 - accuracy: 1.0000 - val_loss: 0.1193 - val_accuracy: 0.9808 - lr: 5.0000e-05\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0044 - accuracy: 0.9987 - val_loss: 0.1189 - val_accuracy: 0.9789 - lr: 5.0000e-05\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.6528e-04 - accuracy: 1.0000 - val_loss: 0.1097 - val_accuracy: 0.9812 - lr: 5.0000e-05\n",
      "Epoch 37/100\n",
      "398/399 [============================>.] - ETA: 0s - loss: 1.7727e-04 - accuracy: 1.0000\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.7711e-04 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9816 - lr: 5.0000e-05\n",
      "Epoch 38/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.4666e-04 - accuracy: 1.0000 - val_loss: 0.1084 - val_accuracy: 0.9817 - lr: 2.5000e-05\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.3320e-04 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9816 - lr: 2.5000e-05\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.2152e-04 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9819 - lr: 2.5000e-05\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.1144e-04 - accuracy: 1.0000 - val_loss: 0.1104 - val_accuracy: 0.9816 - lr: 2.5000e-05\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.0159e-04 - accuracy: 1.0000 - val_loss: 0.1116 - val_accuracy: 0.9816 - lr: 2.5000e-05\n",
      "Epoch 43/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 9.3160e-05 - accuracy: 1.0000 - val_loss: 0.1128 - val_accuracy: 0.9816 - lr: 2.5000e-05\n",
      "Epoch 44/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 8.4842e-05 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9814 - lr: 2.5000e-05\n",
      "Epoch 45/100\n",
      "384/399 [===========================>..] - ETA: 0s - loss: 7.6060e-05 - accuracy: 1.0000\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.6661e-05 - accuracy: 1.0000 - val_loss: 0.1147 - val_accuracy: 0.9817 - lr: 2.5000e-05\n",
      "Epoch 46/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.1112e-05 - accuracy: 1.0000 - val_loss: 0.1142 - val_accuracy: 0.9818 - lr: 1.2500e-05\n",
      "Epoch 47/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.6636e-05 - accuracy: 1.0000 - val_loss: 0.1149 - val_accuracy: 0.9818 - lr: 1.2500e-05\n",
      "Epoch 48/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.3196e-05 - accuracy: 1.0000 - val_loss: 0.1161 - val_accuracy: 0.9816 - lr: 1.2500e-05\n",
      "Epoch 49/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.9074e-05 - accuracy: 1.0000 - val_loss: 0.1164 - val_accuracy: 0.9821 - lr: 1.2500e-05\n",
      "Epoch 50/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.5187e-05 - accuracy: 1.0000 - val_loss: 0.1176 - val_accuracy: 0.9818 - lr: 1.2500e-05\n",
      "Epoch 51/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.1374e-05 - accuracy: 1.0000 - val_loss: 0.1185 - val_accuracy: 0.9818 - lr: 1.2500e-05\n",
      "Epoch 52/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.7411e-05 - accuracy: 1.0000 - val_loss: 0.1197 - val_accuracy: 0.9820 - lr: 1.2500e-05\n",
      "Epoch 53/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.4127e-05 - accuracy: 1.0000 - val_loss: 0.1207 - val_accuracy: 0.9819 - lr: 1.2500e-05\n",
      "Epoch 54/100\n",
      "399/399 [==============================] - ETA: 0s - loss: 4.0496e-05 - accuracy: 1.0000\n",
      "Epoch 54: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.0496e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9820 - lr: 1.2500e-05\n",
      "Epoch 55/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.7297e-05 - accuracy: 1.0000 - val_loss: 0.1214 - val_accuracy: 0.9816 - lr: 6.2500e-06\n",
      "Epoch 56/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.5081e-05 - accuracy: 1.0000 - val_loss: 0.1220 - val_accuracy: 0.9814 - lr: 6.2500e-06\n",
      "Epoch 57/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.3302e-05 - accuracy: 1.0000 - val_loss: 0.1226 - val_accuracy: 0.9816 - lr: 6.2500e-06\n",
      "Epoch 58/100\n",
      "399/399 [==============================] - 1s 4ms/step - loss: 3.1706e-05 - accuracy: 1.0000 - val_loss: 0.1236 - val_accuracy: 0.9816 - lr: 6.2500e-06\n",
      "Epoch 59/100\n",
      "398/399 [============================>.] - ETA: 0s - loss: 2.9541e-05 - accuracy: 1.0000\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 3.12499992105586e-06.\n",
      "Restoring model weights from the end of the best epoch: 49.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.9533e-05 - accuracy: 1.0000 - val_loss: 0.1242 - val_accuracy: 0.9814 - lr: 6.2500e-06\n",
      "Epoch 59: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_5/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_6\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 4s 5ms/step - loss: 0.4995 - accuracy: 0.8748 - val_loss: 0.2267 - val_accuracy: 0.9379 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1817 - accuracy: 0.9476 - val_loss: 0.1644 - val_accuracy: 0.9544 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1295 - accuracy: 0.9625 - val_loss: 0.1335 - val_accuracy: 0.9631 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 2s 3ms/step - loss: 0.0987 - accuracy: 0.9720 - val_loss: 0.1164 - val_accuracy: 0.9672 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0784 - accuracy: 0.9773 - val_loss: 0.1032 - val_accuracy: 0.9701 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0636 - accuracy: 0.9820 - val_loss: 0.0986 - val_accuracy: 0.9712 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0513 - accuracy: 0.9857 - val_loss: 0.0912 - val_accuracy: 0.9739 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0421 - accuracy: 0.9883 - val_loss: 0.0875 - val_accuracy: 0.9752 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0340 - accuracy: 0.9912 - val_loss: 0.0830 - val_accuracy: 0.9761 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9927 - val_loss: 0.0814 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0219 - accuracy: 0.9948 - val_loss: 0.0827 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0181 - accuracy: 0.9961 - val_loss: 0.0862 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.0784 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 2s 5ms/step - loss: 0.0107 - accuracy: 0.9982 - val_loss: 0.0818 - val_accuracy: 0.9797 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0852 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0876 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9993 - val_loss: 0.0904 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "390/399 [============================>.] - ETA: 0s - loss: 0.0053 - accuracy: 0.9992\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0938 - val_accuracy: 0.9789 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0026 - accuracy: 0.9998 - val_loss: 0.0900 - val_accuracy: 0.9810 - lr: 5.0000e-05\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0017 - accuracy: 0.9999 - val_loss: 0.0914 - val_accuracy: 0.9807 - lr: 5.0000e-05\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0919 - val_accuracy: 0.9811 - lr: 5.0000e-05\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.0930 - val_accuracy: 0.9810 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0965 - val_accuracy: 0.9811 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 8.9906e-04 - accuracy: 1.0000 - val_loss: 0.0958 - val_accuracy: 0.9814 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.5163e-04 - accuracy: 1.0000 - val_loss: 0.0986 - val_accuracy: 0.9816 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.3435e-04 - accuracy: 1.0000 - val_loss: 0.1000 - val_accuracy: 0.9814 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.4057e-04 - accuracy: 1.0000 - val_loss: 0.1026 - val_accuracy: 0.9810 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.9610e-04 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9813 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.0898e-04 - accuracy: 1.0000 - val_loss: 0.1040 - val_accuracy: 0.9807 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "382/399 [===========================>..] - ETA: 0s - loss: 3.1704e-04 - accuracy: 1.0000\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.1514e-04 - accuracy: 1.0000 - val_loss: 0.1098 - val_accuracy: 0.9811 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.4626e-04 - accuracy: 1.0000 - val_loss: 0.1094 - val_accuracy: 0.9816 - lr: 2.5000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.1438e-04 - accuracy: 1.0000 - val_loss: 0.1101 - val_accuracy: 0.9820 - lr: 2.5000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.8969e-04 - accuracy: 1.0000 - val_loss: 0.1107 - val_accuracy: 0.9822 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.6772e-04 - accuracy: 1.0000 - val_loss: 0.1132 - val_accuracy: 0.9821 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.5161e-04 - accuracy: 1.0000 - val_loss: 0.1150 - val_accuracy: 0.9819 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.3770e-04 - accuracy: 1.0000 - val_loss: 0.1168 - val_accuracy: 0.9819 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.1539e-04 - accuracy: 1.0000 - val_loss: 0.1169 - val_accuracy: 0.9821 - lr: 2.5000e-05\n",
      "Epoch 38/100\n",
      "388/399 [============================>.] - ETA: 0s - loss: 9.0884e-04 - accuracy: 0.9998\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 8.9373e-04 - accuracy: 0.9998 - val_loss: 0.1159 - val_accuracy: 0.9803 - lr: 2.5000e-05\n",
      "Epoch 39/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.4981e-04 - accuracy: 1.0000 - val_loss: 0.1127 - val_accuracy: 0.9806 - lr: 1.2500e-05\n",
      "Epoch 40/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.4275e-04 - accuracy: 1.0000 - val_loss: 0.1126 - val_accuracy: 0.9811 - lr: 1.2500e-05\n",
      "Epoch 41/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.2472e-04 - accuracy: 1.0000 - val_loss: 0.1130 - val_accuracy: 0.9811 - lr: 1.2500e-05\n",
      "Epoch 42/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.1312e-04 - accuracy: 1.0000 - val_loss: 0.1134 - val_accuracy: 0.9814 - lr: 1.2500e-05\n",
      "Epoch 43/100\n",
      "380/399 [===========================>..] - ETA: 0s - loss: 1.0493e-04 - accuracy: 1.0000\n",
      "Epoch 43: ReduceLROnPlateau reducing learning rate to 6.24999984211172e-06.\n",
      "Restoring model weights from the end of the best epoch: 33.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.0430e-04 - accuracy: 1.0000 - val_loss: 0.1140 - val_accuracy: 0.9813 - lr: 1.2500e-05\n",
      "Epoch 43: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_6/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_7\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 4ms/step - loss: 0.5117 - accuracy: 0.8697 - val_loss: 0.2307 - val_accuracy: 0.9352 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1863 - accuracy: 0.9460 - val_loss: 0.1663 - val_accuracy: 0.9549 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1325 - accuracy: 0.9611 - val_loss: 0.1316 - val_accuracy: 0.9628 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1037 - accuracy: 0.9695 - val_loss: 0.1151 - val_accuracy: 0.9660 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0818 - accuracy: 0.9765 - val_loss: 0.1021 - val_accuracy: 0.9693 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0677 - accuracy: 0.9806 - val_loss: 0.0953 - val_accuracy: 0.9713 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0544 - accuracy: 0.9845 - val_loss: 0.0929 - val_accuracy: 0.9727 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0450 - accuracy: 0.9875 - val_loss: 0.0911 - val_accuracy: 0.9734 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0376 - accuracy: 0.9894 - val_loss: 0.0896 - val_accuracy: 0.9741 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0310 - accuracy: 0.9916 - val_loss: 0.0876 - val_accuracy: 0.9752 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0245 - accuracy: 0.9938 - val_loss: 0.0838 - val_accuracy: 0.9760 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0209 - accuracy: 0.9946 - val_loss: 0.0846 - val_accuracy: 0.9761 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0157 - accuracy: 0.9964 - val_loss: 0.0813 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0127 - accuracy: 0.9974 - val_loss: 0.0875 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 0.0851 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0085 - accuracy: 0.9982 - val_loss: 0.0834 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0059 - accuracy: 0.9991 - val_loss: 0.0886 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0049 - accuracy: 0.9995 - val_loss: 0.0886 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9994 - val_loss: 0.0990 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0081 - accuracy: 0.9979 - val_loss: 0.0951 - val_accuracy: 0.9782 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "390/399 [============================>.] - ETA: 0s - loss: 0.0037 - accuracy: 0.9995\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0037 - accuracy: 0.9995 - val_loss: 0.0995 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 0.9790 - lr: 5.0000e-05\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0969 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 8.6757e-04 - accuracy: 1.0000 - val_loss: 0.0993 - val_accuracy: 0.9789 - lr: 5.0000e-05\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 7.5298e-04 - accuracy: 1.0000 - val_loss: 0.1012 - val_accuracy: 0.9788 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.5154e-04 - accuracy: 1.0000 - val_loss: 0.1017 - val_accuracy: 0.9783 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.6772e-04 - accuracy: 1.0000 - val_loss: 0.1036 - val_accuracy: 0.9783 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "396/399 [============================>.] - ETA: 0s - loss: 4.8242e-04 - accuracy: 1.0000\n",
      "Epoch 28: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.8333e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.1368e-04 - accuracy: 1.0000 - val_loss: 0.1062 - val_accuracy: 0.9789 - lr: 2.5000e-05\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.7314e-04 - accuracy: 1.0000 - val_loss: 0.1075 - val_accuracy: 0.9788 - lr: 2.5000e-05\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.4008e-04 - accuracy: 1.0000 - val_loss: 0.1091 - val_accuracy: 0.9791 - lr: 2.5000e-05\n",
      "Epoch 32/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.0788e-04 - accuracy: 1.0000 - val_loss: 0.1106 - val_accuracy: 0.9788 - lr: 2.5000e-05\n",
      "Epoch 33/100\n",
      "397/399 [============================>.] - ETA: 0s - loss: 2.7761e-04 - accuracy: 1.0000\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.7803e-04 - accuracy: 1.0000 - val_loss: 0.1108 - val_accuracy: 0.9788 - lr: 2.5000e-05\n",
      "Epoch 33: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_7/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_8\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 3ms/step - loss: 0.5106 - accuracy: 0.8720 - val_loss: 0.2273 - val_accuracy: 0.9377 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1812 - accuracy: 0.9475 - val_loss: 0.1602 - val_accuracy: 0.9571 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1299 - accuracy: 0.9624 - val_loss: 0.1347 - val_accuracy: 0.9628 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0990 - accuracy: 0.9715 - val_loss: 0.1148 - val_accuracy: 0.9677 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0800 - accuracy: 0.9767 - val_loss: 0.1085 - val_accuracy: 0.9690 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0642 - accuracy: 0.9818 - val_loss: 0.1006 - val_accuracy: 0.9719 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0528 - accuracy: 0.9854 - val_loss: 0.0915 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0444 - accuracy: 0.9876 - val_loss: 0.0925 - val_accuracy: 0.9741 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0352 - accuracy: 0.9906 - val_loss: 0.0865 - val_accuracy: 0.9748 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0287 - accuracy: 0.9923 - val_loss: 0.0890 - val_accuracy: 0.9742 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0244 - accuracy: 0.9935 - val_loss: 0.0832 - val_accuracy: 0.9762 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0183 - accuracy: 0.9957 - val_loss: 0.0838 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0149 - accuracy: 0.9969 - val_loss: 0.0847 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0116 - accuracy: 0.9979 - val_loss: 0.0810 - val_accuracy: 0.9772 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0094 - accuracy: 0.9984 - val_loss: 0.0924 - val_accuracy: 0.9768 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0891 - val_accuracy: 0.9773 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0057 - accuracy: 0.9991 - val_loss: 0.0850 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0932 - val_accuracy: 0.9767 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0040 - accuracy: 0.9996 - val_loss: 0.0924 - val_accuracy: 0.9793 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0041 - accuracy: 0.9993 - val_loss: 0.0975 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0047 - accuracy: 0.9990 - val_loss: 0.0961 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0046 - accuracy: 0.9990 - val_loss: 0.1201 - val_accuracy: 0.9736 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0048 - accuracy: 0.9990 - val_loss: 0.1001 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "392/399 [============================>.] - ETA: 0s - loss: 9.6717e-04 - accuracy: 1.0000\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 9.6179e-04 - accuracy: 1.0000 - val_loss: 0.0970 - val_accuracy: 0.9786 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.3440e-04 - accuracy: 1.0000 - val_loss: 0.0989 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 5.3573e-04 - accuracy: 1.0000 - val_loss: 0.0995 - val_accuracy: 0.9791 - lr: 5.0000e-05\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.6699e-04 - accuracy: 1.0000 - val_loss: 0.1019 - val_accuracy: 0.9800 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.2279e-04 - accuracy: 1.0000 - val_loss: 0.1015 - val_accuracy: 0.9796 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.5769e-04 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9790 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.1655e-04 - accuracy: 1.0000 - val_loss: 0.1039 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.7773e-04 - accuracy: 1.0000 - val_loss: 0.1055 - val_accuracy: 0.9793 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "392/399 [============================>.] - ETA: 0s - loss: 2.4093e-04 - accuracy: 1.0000\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.4029e-04 - accuracy: 1.0000 - val_loss: 0.1080 - val_accuracy: 0.9791 - lr: 5.0000e-05\n",
      "Epoch 33/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.0630e-04 - accuracy: 1.0000 - val_loss: 0.1090 - val_accuracy: 0.9796 - lr: 2.5000e-05\n",
      "Epoch 34/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.8944e-04 - accuracy: 1.0000 - val_loss: 0.1109 - val_accuracy: 0.9792 - lr: 2.5000e-05\n",
      "Epoch 35/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.7295e-04 - accuracy: 1.0000 - val_loss: 0.1114 - val_accuracy: 0.9793 - lr: 2.5000e-05\n",
      "Epoch 36/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.5636e-04 - accuracy: 1.0000 - val_loss: 0.1124 - val_accuracy: 0.9791 - lr: 2.5000e-05\n",
      "Epoch 37/100\n",
      "395/399 [============================>.] - ETA: 0s - loss: 1.4124e-04 - accuracy: 1.0000\n",
      "Epoch 37: ReduceLROnPlateau reducing learning rate to 1.249999968422344e-05.\n",
      "Restoring model weights from the end of the best epoch: 27.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.4105e-04 - accuracy: 1.0000 - val_loss: 0.1131 - val_accuracy: 0.9792 - lr: 2.5000e-05\n",
      "Epoch 37: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_8/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_9\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 3ms/step - loss: 0.4986 - accuracy: 0.8752 - val_loss: 0.2347 - val_accuracy: 0.9364 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1796 - accuracy: 0.9480 - val_loss: 0.1643 - val_accuracy: 0.9551 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1278 - accuracy: 0.9635 - val_loss: 0.1343 - val_accuracy: 0.9610 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0989 - accuracy: 0.9718 - val_loss: 0.1153 - val_accuracy: 0.9654 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0777 - accuracy: 0.9776 - val_loss: 0.1001 - val_accuracy: 0.9703 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0617 - accuracy: 0.9821 - val_loss: 0.0958 - val_accuracy: 0.9720 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0506 - accuracy: 0.9855 - val_loss: 0.0905 - val_accuracy: 0.9733 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0404 - accuracy: 0.9892 - val_loss: 0.0872 - val_accuracy: 0.9747 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0323 - accuracy: 0.9909 - val_loss: 0.0861 - val_accuracy: 0.9754 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0264 - accuracy: 0.9929 - val_loss: 0.0870 - val_accuracy: 0.9759 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0212 - accuracy: 0.9952 - val_loss: 0.0882 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0172 - accuracy: 0.9963 - val_loss: 0.0909 - val_accuracy: 0.9758 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0137 - accuracy: 0.9968 - val_loss: 0.0886 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0835 - val_accuracy: 0.9788 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0080 - accuracy: 0.9988 - val_loss: 0.0870 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0071 - accuracy: 0.9988 - val_loss: 0.0903 - val_accuracy: 0.9779 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9988 - val_loss: 0.0953 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0919 - val_accuracy: 0.9793 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0030 - accuracy: 0.9997 - val_loss: 0.0959 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0029 - accuracy: 0.9996 - val_loss: 0.1019 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0061 - accuracy: 0.9985 - val_loss: 0.0960 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0028 - accuracy: 0.9995 - val_loss: 0.0959 - val_accuracy: 0.9809 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.0987 - val_accuracy: 0.9798 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.2034e-04 - accuracy: 1.0000 - val_loss: 0.1010 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.7900e-04 - accuracy: 1.0000 - val_loss: 0.1035 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.7529e-04 - accuracy: 1.0000 - val_loss: 0.1056 - val_accuracy: 0.9799 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "385/399 [===========================>..] - ETA: 0s - loss: 3.2159e-04 - accuracy: 1.0000\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.2008e-04 - accuracy: 1.0000 - val_loss: 0.1092 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.6148e-04 - accuracy: 1.0000 - val_loss: 0.1096 - val_accuracy: 0.9796 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.2972e-04 - accuracy: 1.0000 - val_loss: 0.1112 - val_accuracy: 0.9791 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.0133e-04 - accuracy: 1.0000 - val_loss: 0.1123 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.7617e-04 - accuracy: 1.0000 - val_loss: 0.1137 - val_accuracy: 0.9790 - lr: 5.0000e-05\n",
      "Epoch 32/100\n",
      "392/399 [============================>.] - ETA: 0s - loss: 1.5742e-04 - accuracy: 1.0000\n",
      "Epoch 32: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Restoring model weights from the end of the best epoch: 22.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 1.5741e-04 - accuracy: 1.0000 - val_loss: 0.1160 - val_accuracy: 0.9797 - lr: 5.0000e-05\n",
      "Epoch 32: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_9/saved_models\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_10\n",
      "Epoch 1/100\n",
      "399/399 [==============================] - 3s 3ms/step - loss: 0.5117 - accuracy: 0.8716 - val_loss: 0.2375 - val_accuracy: 0.9332 - lr: 1.0000e-04\n",
      "Epoch 2/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1792 - accuracy: 0.9475 - val_loss: 0.1617 - val_accuracy: 0.9563 - lr: 1.0000e-04\n",
      "Epoch 3/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9633 - val_loss: 0.1306 - val_accuracy: 0.9640 - lr: 1.0000e-04\n",
      "Epoch 4/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0974 - accuracy: 0.9725 - val_loss: 0.1109 - val_accuracy: 0.9684 - lr: 1.0000e-04\n",
      "Epoch 5/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0774 - accuracy: 0.9779 - val_loss: 0.1070 - val_accuracy: 0.9689 - lr: 1.0000e-04\n",
      "Epoch 6/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0623 - accuracy: 0.9825 - val_loss: 0.1043 - val_accuracy: 0.9692 - lr: 1.0000e-04\n",
      "Epoch 7/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0504 - accuracy: 0.9860 - val_loss: 0.0905 - val_accuracy: 0.9733 - lr: 1.0000e-04\n",
      "Epoch 8/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0409 - accuracy: 0.9889 - val_loss: 0.0881 - val_accuracy: 0.9754 - lr: 1.0000e-04\n",
      "Epoch 9/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0337 - accuracy: 0.9911 - val_loss: 0.0879 - val_accuracy: 0.9757 - lr: 1.0000e-04\n",
      "Epoch 10/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0278 - accuracy: 0.9931 - val_loss: 0.0813 - val_accuracy: 0.9776 - lr: 1.0000e-04\n",
      "Epoch 11/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0218 - accuracy: 0.9947 - val_loss: 0.0877 - val_accuracy: 0.9764 - lr: 1.0000e-04\n",
      "Epoch 12/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0176 - accuracy: 0.9960 - val_loss: 0.0909 - val_accuracy: 0.9756 - lr: 1.0000e-04\n",
      "Epoch 13/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0150 - accuracy: 0.9967 - val_loss: 0.0834 - val_accuracy: 0.9780 - lr: 1.0000e-04\n",
      "Epoch 14/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0115 - accuracy: 0.9978 - val_loss: 0.0899 - val_accuracy: 0.9769 - lr: 1.0000e-04\n",
      "Epoch 15/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0088 - accuracy: 0.9986 - val_loss: 0.0873 - val_accuracy: 0.9781 - lr: 1.0000e-04\n",
      "Epoch 16/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0066 - accuracy: 0.9991 - val_loss: 0.0899 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 17/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0908 - val_accuracy: 0.9784 - lr: 1.0000e-04\n",
      "Epoch 18/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0051 - accuracy: 0.9990 - val_loss: 0.0962 - val_accuracy: 0.9777 - lr: 1.0000e-04\n",
      "Epoch 19/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0058 - accuracy: 0.9988 - val_loss: 0.0904 - val_accuracy: 0.9794 - lr: 1.0000e-04\n",
      "Epoch 20/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0023 - accuracy: 0.9998 - val_loss: 0.0928 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 21/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0015 - accuracy: 0.9999 - val_loss: 0.0989 - val_accuracy: 0.9796 - lr: 1.0000e-04\n",
      "Epoch 22/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0042 - accuracy: 0.9988 - val_loss: 0.1116 - val_accuracy: 0.9744 - lr: 1.0000e-04\n",
      "Epoch 23/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0060 - accuracy: 0.9985 - val_loss: 0.0979 - val_accuracy: 0.9783 - lr: 1.0000e-04\n",
      "Epoch 24/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.1003 - val_accuracy: 0.9787 - lr: 1.0000e-04\n",
      "Epoch 25/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 6.0169e-04 - accuracy: 1.0000 - val_loss: 0.1018 - val_accuracy: 0.9790 - lr: 1.0000e-04\n",
      "Epoch 26/100\n",
      "389/399 [============================>.] - ETA: 0s - loss: 4.6315e-04 - accuracy: 1.0000\n",
      "Epoch 26: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 4.6495e-04 - accuracy: 1.0000 - val_loss: 0.1037 - val_accuracy: 0.9791 - lr: 1.0000e-04\n",
      "Epoch 27/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.7894e-04 - accuracy: 1.0000 - val_loss: 0.1042 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 28/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 3.3559e-04 - accuracy: 1.0000 - val_loss: 0.1057 - val_accuracy: 0.9791 - lr: 5.0000e-05\n",
      "Epoch 29/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.9743e-04 - accuracy: 1.0000 - val_loss: 0.1072 - val_accuracy: 0.9791 - lr: 5.0000e-05\n",
      "Epoch 30/100\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.6363e-04 - accuracy: 1.0000 - val_loss: 0.1076 - val_accuracy: 0.9790 - lr: 5.0000e-05\n",
      "Epoch 31/100\n",
      "388/399 [============================>.] - ETA: 0s - loss: 2.3512e-04 - accuracy: 1.0000\n",
      "Epoch 31: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "Restoring model weights from the end of the best epoch: 21.\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 2.3439e-04 - accuracy: 1.0000 - val_loss: 0.1095 - val_accuracy: 0.9792 - lr: 5.0000e-05\n",
      "Epoch 31: early stopping\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_10/saved_models\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "    \n",
    "    model = create_model()\n",
    "    \n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-4), loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
    "    history = model.fit(ds_train, validation_data=ds_val, epochs=100, callbacks=[lr_scheduler, early_stop])\n",
    "    \n",
    "    if not os.path.exists(exp_name+'/saved_models'):\n",
    "        print(\"Making directory\", exp_name+'/saved_models')\n",
    "        os.makedirs(exp_name+'/saved_models')\n",
    "\n",
    "    model.save_weights(f'{exp_name}/saved_models/trained_weights.h5')\n",
    "    with open(f'{exp_name}/history.pickle', 'wb') as f:\n",
    "        pickle.dump(history, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dbb79699",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 7.8377e-04 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0936 - accuracy: 0.9802\n",
      "79/79 [==============================] - 0s 3ms/step - loss: 0.0830 - accuracy: 0.9808\n",
      "Run: 2\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 8.4967e-04 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9814\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9805\n",
      "Run: 3\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 1.9078e-04 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9807\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1004 - accuracy: 0.9799\n",
      "Run: 4\n",
      "399/399 [==============================] - 1s 3ms/step - loss: 8.3209e-04 - accuracy: 0.9999\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9797\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0859 - accuracy: 0.9809\n",
      "Run: 5\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 6.1507e-05 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1164 - accuracy: 0.9821\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9809\n",
      "Run: 6\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 3.0854e-04 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9822\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9794\n",
      "Run: 7\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0012 - accuracy: 0.9999\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0969 - accuracy: 0.9792\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0793 - accuracy: 0.9813\n",
      "Run: 8\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 7.6410e-04 - accuracy: 1.0000\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.1019 - accuracy: 0.9800\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9793\n",
      "Run: 9\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0014 - accuracy: 0.9999\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9809\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0931 - accuracy: 0.9805\n",
      "Run: 10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 0.0016 - accuracy: 0.9999\n",
      "71/71 [==============================] - 0s 2ms/step - loss: 0.0989 - accuracy: 0.9796\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0858 - accuracy: 0.9797\n",
      "Average train error: 0.00 (0.00)\n",
      "Average validation error: 1.94 (0.10)\n",
      "Average test error: 1.97 (0.07)\n"
     ]
    }
   ],
   "source": [
    "train_acc = []\n",
    "val_acc = []\n",
    "test_acc = []\n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-4), loss=loss_fn, metrics=['accuracy'])\n",
    "    train_acc.append(model.evaluate(ds_train, verbose=1)[1])\n",
    "    val_acc.append(model.evaluate(ds_val, verbose=1)[1])\n",
    "    test_acc.append(model.evaluate(ds_test, verbose=1)[1])\n",
    "print(f'Average train error: {(100-np.mean(train_acc)*100):.2f} ({(np.std(train_acc)*100):.2f})')\n",
    "print(f'Average validation error: {(100-np.mean(val_acc)*100):.2f} ({(np.std(val_acc)*100):.2f})')\n",
    "print(f'Average test error: {(100-np.mean(test_acc)*100):.2f} ({(np.std(test_acc)*100):.2f})')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4645ee88",
   "metadata": {},
   "source": [
    "### PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5be56e2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   0%|          | 1/200 [00:04<13:54,  4.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   1%|          | 2/200 [00:05<08:27,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:07<06:56,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 4/200 [00:08<06:00,  1.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▎         | 5/200 [00:10<05:28,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   5%|▌         | 10/200 [00:15<03:29,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   6%|▌         | 11/200 [00:16<03:47,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   6%|▌         | 12/200 [00:18<03:58,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   6%|▋         | 13/200 [00:19<04:05,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_1/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  12%|█▏        | 23/200 [00:30<03:57,  1.34s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 133.03it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 603.29it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 627.52it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 637.94it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 637.09it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 627.59it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 636.56it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 634.98it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 651.41it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 649.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 255.47it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 618.65it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 633.93it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 637.08it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 672.23it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 675.76it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 652.69it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 585.62it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 658.41it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 663.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 2\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   1%|          | 2/200 [00:05<07:24,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:06<06:36,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▎         | 5/200 [00:09<04:52,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:10<04:44,  1.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▎         | 7/200 [00:11<04:39,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▍         | 8/200 [00:13<04:37,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 16/200 [00:21<03:04,  1.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 17/200 [00:22<03:26,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   9%|▉         | 18/200 [00:24<03:39,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  10%|▉         | 19/200 [00:25<03:49,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  10%|█         | 21/200 [00:28<03:34,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_2/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  16%|█▌        | 31/200 [00:39<03:33,  1.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 137.99it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 624.25it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 644.00it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 642.17it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 650.58it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 592.91it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 679.64it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 664.51it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 677.02it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 675.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 41.41it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 643.41it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 659.21it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 666.66it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 661.34it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 666.04it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 669.18it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 664.31it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 670.60it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 664.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 3\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_3/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_3/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_3/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   5%|▌         | 10/200 [00:14<04:29,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 151.16it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 641.55it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 664.84it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 664.78it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 675.96it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 685.92it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 664.79it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 688.64it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 681.89it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 680.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 258.02it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 656.11it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 682.78it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 689.10it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 688.03it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 683.23it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 672.54it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 683.96it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 686.85it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 680.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 4\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   1%|          | 2/200 [00:05<07:25,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 4/200 [00:07<04:55,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▎         | 5/200 [00:08<04:45,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:10<04:40,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▎         | 7/200 [00:11<04:36,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▍         | 8/200 [00:13<04:32,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_4/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   9%|▉         | 18/200 [00:24<04:05,  1.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 149.20it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 620.95it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 639.95it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 654.81it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 660.01it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 670.61it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 655.58it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 660.24it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 667.13it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 663.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 263.43it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 613.35it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 649.92it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 641.69it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 652.86it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 651.80it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 634.93it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 668.36it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 663.26it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 664.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 5\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:05<05:21,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 4/200 [00:07<05:00,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:09<04:12,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▎         | 7/200 [00:11<04:16,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_5/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 17/200 [00:21<03:54,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 147.95it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 642.67it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 677.33it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 685.43it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 677.57it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 678.97it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 668.30it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 686.93it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 662.10it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 697.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 252.77it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 668.36it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 688.73it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 677.44it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 691.59it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 688.61it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 686.29it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 694.18it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 697.99it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 612.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 6\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   1%|          | 2/200 [00:04<07:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:06<06:30,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▎         | 5/200 [00:09<04:43,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:10<04:38,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▎         | 7/200 [00:11<04:34,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▍         | 8/200 [00:13<04:32,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▍         | 9/200 [00:14<04:30,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   5%|▌         | 10/200 [00:16<04:28,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  10%|▉         | 19/200 [00:24<02:55,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  10%|█         | 20/200 [00:26<03:18,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  12%|█▏        | 23/200 [00:29<03:08,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  12%|█▏        | 24/200 [00:31<03:23,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  13%|█▎        | 26/200 [00:33<03:19,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  14%|█▍        | 29/200 [00:37<03:13,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_6/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  20%|█▉        | 39/200 [00:47<03:18,  1.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 150.99it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 627.55it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 654.01it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 654.28it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 658.25it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 662.92it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 670.79it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 662.86it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 665.93it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 658.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 248.85it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 646.55it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 657.58it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 666.84it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 671.01it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 668.83it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 668.68it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 672.61it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 661.85it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 679.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 7\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   0%|          | 1/200 [00:04<13:18,  4.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:06<05:52,  1.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 4/200 [00:07<05:20,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▎         | 5/200 [00:09<05:01,  1.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:10<04:49,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 15/200 [00:19<03:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_7/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  12%|█▎        | 25/200 [00:30<03:33,  1.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 144.57it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 631.64it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 614.54it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 653.62it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 648.68it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 660.55it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 658.21it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 657.95it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 657.79it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 653.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 256.67it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 646.86it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 619.54it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 666.84it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 670.09it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 674.31it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 673.33it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 629.01it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 658.33it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 651.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 8\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   1%|          | 2/200 [00:05<08:01,  2.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:06<06:25,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:10<04:07,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▎         | 7/200 [00:11<04:13,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▍         | 8/200 [00:12<04:15,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   6%|▌         | 12/200 [00:17<03:26,  1.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   6%|▋         | 13/200 [00:18<03:43,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   7%|▋         | 14/200 [00:20<03:55,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 15/200 [00:21<04:03,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 16/200 [00:22<04:05,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_8/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  13%|█▎        | 26/200 [00:34<03:47,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 145.73it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 630.78it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 655.77it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 661.37it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 675.48it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 673.96it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 675.02it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 676.36it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 677.06it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 680.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 263.61it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 654.22it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 659.10it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 678.51it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 681.93it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 681.61it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 675.65it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 678.47it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 672.77it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 669.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 9\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   1%|          | 2/200 [00:04<07:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 3/200 [00:06<06:00,  1.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▏         | 4/200 [00:07<05:26,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_9/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   7%|▋         | 14/200 [00:18<04:06,  1.33s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 149.82it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 650.89it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 685.38it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 680.61it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 686.68it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 687.27it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 682.68it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 670.33it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 672.81it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 676.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 251.72it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 652.84it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 634.67it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 670.71it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 683.22it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 671.60it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 675.40it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 675.38it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 677.54it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 677.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js\n",
      "Training PMI model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|          | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   2%|▎         | 5/200 [00:07<03:56,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   3%|▎         | 6/200 [00:09<04:06,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   4%|▎         | 7/200 [00:10<04:11,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   7%|▋         | 14/200 [00:17<03:03,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 15/200 [00:19<03:44,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:   8%|▊         | 16/200 [00:20<03:52,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ../results/PI_Explainability/mlp_mnist/run_10/calibration/pmi/separable_variational_f_js/pmi_output_model/assets\n",
      "Epochs:  13%|█▎        | 26/200 [00:31<03:30,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all validation samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 9/9 [00:00<00:00, 149.68it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 9/9 [00:00<00:00, 636.60it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 9/9 [00:00<00:00, 637.08it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 9/9 [00:00<00:00, 661.42it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 9/9 [00:00<00:00, 667.01it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 9/9 [00:00<00:00, 676.68it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 9/9 [00:00<00:00, 670.64it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 9/9 [00:00<00:00, 672.25it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 9/9 [00:00<00:00, 680.92it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 9/9 [00:00<00:00, 672.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PMI for all test samples and for all classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing PMI for class 1: 100%|██████████| 10/10 [00:00<00:00, 266.52it/s]\n",
      "Computing PMI for class 2: 100%|██████████| 10/10 [00:00<00:00, 661.42it/s]\n",
      "Computing PMI for class 3: 100%|██████████| 10/10 [00:00<00:00, 677.63it/s]\n",
      "Computing PMI for class 4: 100%|██████████| 10/10 [00:00<00:00, 679.15it/s]\n",
      "Computing PMI for class 5: 100%|██████████| 10/10 [00:00<00:00, 680.98it/s]\n",
      "Computing PMI for class 6: 100%|██████████| 10/10 [00:00<00:00, 692.98it/s]\n",
      "Computing PMI for class 7: 100%|██████████| 10/10 [00:00<00:00, 680.54it/s]\n",
      "Computing PMI for class 8: 100%|██████████| 10/10 [00:00<00:00, 689.09it/s]\n",
      "Computing PMI for class 9: 100%|██████████| 10/10 [00:00<00:00, 555.54it/s]\n",
      "Computing PMI for class 10: 100%|██████████| 10/10 [00:00<00:00, 661.69it/s]\n"
     ]
    }
   ],
   "source": [
    "from src.pmi_estimators import train_critic_model, neural_pmi\n",
    "from tqdm import tqdm\n",
    "\n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/separable_variational_f_js'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    int_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "\n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PMI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "\n",
    "    print(f'Training PMI model...')\n",
    "    ds_activity_trn = ds_train.batch(128).map(lambda x, y: (int_model(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    ds_activity_val = ds_val.batch(128).map(lambda x, y: (int_model(x), y)).cache().prefetch(tf.data.AUTOTUNE)\n",
    "    train_critic_model(ds_activity_trn, ds_activity_val, critic='separable', estimator='variational_f_js', epochs=200, save_path=f'{exp_name}/pmi_output_model')\n",
    "\n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PMI for all validation and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "\n",
    "    pmi_model = tf.keras.models.load_model(f'{exp_name}/pmi_output_model')\n",
    "    n_classes = 10\n",
    "\n",
    "    print(f'Computing PMI for all validation samples and for all classes...')\n",
    "    encoded_x = []\n",
    "    for x, _ in ds_val.batch(128):\n",
    "        encoded_x.append(int_model(x).numpy())\n",
    "    encoded_x = np.concatenate(encoded_x)\n",
    "    num_samples = encoded_x.shape[0]\n",
    "    \n",
    "    pmi_class = []\n",
    "    batch_size = 1024\n",
    "    for k in range(n_classes):\n",
    "        num_samples = encoded_x.shape[0]\n",
    "        y_k = tf.one_hot(tf.fill([num_samples], k), depth=n_classes)\n",
    "        pmi_list = []\n",
    "        for i in tqdm(range(0, len(encoded_x), batch_size), desc=f\"Computing PMI for class {k+1}\"):\n",
    "            x_batch = encoded_x[i:i+batch_size]\n",
    "            y_batch = y_k[i:i+batch_size]\n",
    "            pmi = neural_pmi(x_batch, y_batch, pmi_model, estimator='variational_f_js')\n",
    "            pmi_list += np.array(pmi).tolist()\n",
    "        pmi_class.append(pmi_list)\n",
    "    np.save(f'{exp_name}/pmi_output_class_val.npy', np.array(pmi_class).T)\n",
    "    \n",
    "    print(f'Computing PMI for all test samples and for all classes...')\n",
    "    encoded_x = []\n",
    "    for x, _ in ds_test.batch(128):\n",
    "        encoded_x.append(int_model(x).numpy())\n",
    "    encoded_x = np.concatenate(encoded_x)\n",
    "    num_samples = encoded_x.shape[0]\n",
    "    \n",
    "    pmi_class = []\n",
    "    batch_size = 1024\n",
    "    for k in range(n_classes):\n",
    "        num_samples = encoded_x.shape[0]\n",
    "        y_k = tf.one_hot(tf.fill([num_samples], k), depth=n_classes)\n",
    "        pmi_list = []\n",
    "        for i in tqdm(range(0, len(encoded_x), batch_size), desc=f\"Computing PMI for class {k+1}\"):\n",
    "            x_batch = encoded_x[i:i+batch_size]\n",
    "            y_batch = y_k[i:i+batch_size]\n",
    "            pmi = neural_pmi(x_batch, y_batch, pmi_model, estimator='variational_f_js')\n",
    "            pmi_list += np.array(pmi).tolist()\n",
    "        pmi_class.append(pmi_list)\n",
    "    np.save(f'{exp_name}/pmi_output_class_test.npy', np.array(pmi_class).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1405086f",
   "metadata": {},
   "source": [
    "### PSI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde2ecbf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_1/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 267.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 253.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 234.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 2\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_2/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 266.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 252.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 234.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 3\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_3/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 269.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 251.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 235.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 4\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_4/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 269.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 251.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 233.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 5\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_5/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 268.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 252.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 232.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 6\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_6/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 267.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 251.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 233.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 7\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_7/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 265.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 253.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 231.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 8\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_8/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 266.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 252.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 233.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 9\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_9/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 266.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 251.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 233.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 10\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_10/calibration/psi/gaussian\n",
      "Training PSI model (gaussian)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 265.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all validation samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:01, 252.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing PSI for all test samples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Projections: 500it [00:02, 235.07it/s]\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/psi/gaussian'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    int_model = tf.keras.Model(inputs=model.inputs, outputs=model.layers[-1].output)\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PSI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    x_logits_list = []\n",
    "    y_labels_list = []\n",
    "\n",
    "    for x_batch, y_batch in ds_train.batch(256):\n",
    "        logits = int_model(x_batch)\n",
    "        labels = tf.argmax(y_batch, axis=1)\n",
    "        x_logits_list.append(logits)\n",
    "        y_labels_list.append(labels)\n",
    "\n",
    "    x = tf.concat(x_logits_list, axis=0).numpy()\n",
    "    y = tf.concat(y_labels_list, axis=0).numpy()\n",
    "    \n",
    "    print(f'Training PSI model (gaussian)...')\n",
    "    psi_data = psi_gaussian_train(x, y, n_projs=500)\n",
    "    np.save(f'{exp_name}/gaussian_output_model_500_projs.npy', psi_data)\n",
    "\n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PSI for all validation and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "\n",
    "    psi_data = np.load(f'{exp_name}/gaussian_output_model_500_projs.npy', allow_pickle=True).item()\n",
    "\n",
    "    print(f'Computing PSI for all validation samples...')\n",
    "    x_logits_list = []\n",
    "\n",
    "    for x_batch, y_batch in ds_val.batch(256):\n",
    "        logits = int_model(x_batch)\n",
    "        x_logits_list.append(logits)\n",
    "    \n",
    "    x = tf.concat(x_logits_list, axis=0).numpy()\n",
    "    psi_class, pmi_arr = psi_gaussian_val_class(x, psi_data)\n",
    "    np.save(f'{exp_name}/psi_output_class_500_projs_val.npy', np.array(psi_class))\n",
    "\n",
    "    print(f'Computing PSI for all test samples...')\n",
    "    x_logits_list = []\n",
    "\n",
    "    for x_batch, y_batch in ds_test.batch(256):\n",
    "        logits = int_model(x_batch)\n",
    "        x_logits_list.append(logits)\n",
    "    \n",
    "    x = tf.concat(x_logits_list, axis=0).numpy()\n",
    "    psi_class, pmi_arr = psi_gaussian_val_class(x, psi_data)\n",
    "    np.save(f'{exp_name}/psi_output_class_500_projs_test.npy', np.array(psi_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e38a1e3",
   "metadata": {},
   "source": [
    "### PVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5e5928d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 3ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 2\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_2/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 3\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_3/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 4\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_4/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 5\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_5/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 6\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_6/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 3ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "Run: 7\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_7/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 8\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_8/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 9\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_9/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 10\n",
      "Making directory ../results/PI_Explainability/mlp_mnist/run_10/calibration/pvi/training_from_scratch\n",
      "Epoch 1/10\n",
      "399/399 [==============================] - 2s 2ms/step - loss: 2.3017 - accuracy: 0.1114\n",
      "Epoch 2/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 3/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 4/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 5/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 6/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 7/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 8/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 9/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Epoch 10/10\n",
      "399/399 [==============================] - 1s 2ms/step - loss: 2.3013 - accuracy: 0.1122\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "random_runs = list(range(10))\n",
    "while any(random_runs[i] == i for i in range(10)):\n",
    "    np.random.shuffle(random_runs)\n",
    "    \n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{random_runs[run]+1}/saved_models/trained_weights.h5')\n",
    "    pvi_model.save_weights(f'{exp_name}/pvi_model_weights.h5')\n",
    "    \n",
    "    untrained_model = create_model()\n",
    "    train_pvi_null_model(ds_train, untrained_model, epochs=10, save_path=f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'{exp_name}/pvi_model_weights.h5')\n",
    "    null_model = create_model()\n",
    "    null_model.load_weights(f'{exp_name}/pvi_null_model_weights.h5')\n",
    "\n",
    "    true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "    opt_temp_pvi = temp_scaling.temp_scaling_nll(pvi_model.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "    ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "    opt_temp_null = temp_scaling.temp_scaling_nll(null_model.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "\n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_val.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_test.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b569ff4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/finetuned'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "    pvi_model.compile(optimizer=AdamW(learning_rate=1e-4, weight_decay=1e-4), loss=loss_fn, metrics=['accuracy'])\n",
    "\n",
    "    lr_scheduler = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1)\n",
    "    early_stop = EarlyStopping(monitor='val_accuracy', patience=10, restore_best_weights=True, verbose=1)\n",
    "    pvi_model.fit(ds_train.batch(256), validation_data=ds_val.batch(256), epochs=100, callbacks=[lr_scheduler, early_stop])\n",
    "    \n",
    "    pvi_model.save_weights(f'{exp_name}/pvi_model_weights.h5')\n",
    "    \n",
    "    untrained_model = create_model()\n",
    "    untrained_model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_null_model_weights.h5')\n",
    "    untrained_model.save_weights(f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'{exp_name}/pvi_model_weights.h5')\n",
    "    null_model = create_model()\n",
    "    null_model.load_weights(f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "    opt_temp_pvi = temp_scaling.temp_scaling_nll(pvi_model.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "    ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "    opt_temp_null = temp_scaling.temp_scaling_nll(null_model.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "\n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_val.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_test.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1c3c1e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "Run: 2\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "Run: 3\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 4\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 2ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 5\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 6\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 7\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 8\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 9\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 2ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "Run: 10\n",
      "Computing PVI for all validation samples and for all classes...\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "71/71 [==============================] - 0s 1ms/step\n",
      "Computing PVI for all test samples and for all classes...\n",
      "79/79 [==============================] - 0s 1ms/step\n",
      "79/79 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "pvi_runs = [4 if i == 6 else 6 for i in range(10)]\n",
    "    \n",
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{pvi_runs[run]+1}/saved_models/trained_weights.h5')\n",
    "    pvi_model.save_weights(f'{exp_name}/pvi_model_best_weights.h5')\n",
    "    \n",
    "#     untrained_model = create_model()\n",
    "#     train_pvi_null_model(ds_train, untrained_model, epochs=10, save_path=f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model = create_model()\n",
    "    pvi_model.load_weights(f'{exp_name}/pvi_model_best_weights.h5')\n",
    "    null_model = create_model()\n",
    "    null_model.load_weights(f'{exp_name}/pvi_null_model_weights.h5')\n",
    "    \n",
    "    true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "    opt_temp_pvi = temp_scaling.temp_scaling_nll(pvi_model.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "    ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "    opt_temp_null = temp_scaling.temp_scaling_nll(null_model.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "\n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_val.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_best_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = neural_pvi_class(ds_test.batch(128), pvi_model, null_model, opt_temp_pvi, opt_temp_null)\n",
    "    np.save(f'{exp_name}/pvi_class_best_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2cb0bdc",
   "metadata": {},
   "source": [
    "### Ensemble PVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf8e16f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/ensemble_no_training_training_from_scratch'\n",
    "    if not os.path.exists(exp_name):\n",
    "        print(\"Making directory\", exp_name)\n",
    "        os.makedirs(exp_name)\n",
    "        \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Train PVI Model\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    pvi_model_1 = create_model()\n",
    "    pvi_model_1.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    null_model_1 = create_model()\n",
    "    null_model_1.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_null_model_weights.h5')\n",
    "    pvi_model_2 = create_model()\n",
    "    pvi_model_2.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_model_weights.h5')\n",
    "    null_model_2 = create_model()\n",
    "    null_model_2.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch/pvi_null_model_weights.h5')\n",
    "    \n",
    "#     true_y_val = np.argmax([y for x,y in ds_val], axis=1)\n",
    "#     opt_temp_pvi_1 = utils.temp_scaling_nll(pvi_model_1.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "#     opt_temp_pvi_2 = utils.temp_scaling_nll(pvi_model_2.predict(ds_val.batch(128), verbose=0), true_y_val)\n",
    "#     ds_null = ds_val.map(lambda x, y: (tf.zeros_like(x), y))\n",
    "#     opt_temp_null = utils.temp_scaling_nll(null_model_1.predict(ds_null.batch(128), verbose=0), true_y_val)\n",
    "    \n",
    "    ##############################################################\n",
    "    #\n",
    "    # Compute PVI for all training and test samples\n",
    "    #\n",
    "    # #############################################################\n",
    "    \n",
    "    print(f'Computing PVI for all validation samples and for all classes...')\n",
    "    pvi_class = []\n",
    "    for (x_batch, y_batch) in ds_val.batch(256):\n",
    "        pvi = neural_pvi_ensemble_class([x_batch, x_batch], [pvi_model_1, pvi_model_2], [null_model_1, null_model_2])\n",
    "        pvi_class += np.array(pvi).tolist()\n",
    "    np.save(f'{exp_name}/pvi_class_val.npy', np.array(pvi_class))\n",
    "\n",
    "    print(f'Computing PVI for all test samples and for all classes...')\n",
    "    pvi_class = []\n",
    "    for (x_batch, y_batch) in ds_test.batch(256):\n",
    "        pvi = neural_pvi_ensemble_class([x_batch, x_batch], [pvi_model_1, pvi_model_2], [null_model_1, null_model_2])\n",
    "        pvi_class += np.array(pvi).tolist()\n",
    "    np.save(f'{exp_name}/pvi_class_test.npy', np.array(pvi_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29ac1815",
   "metadata": {},
   "source": [
    "### Temp Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75731ae0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 2\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 3\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 4\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 5\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 6\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 7\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 8\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Run: 9\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 10\n",
      "18/18 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    if not os.path.exists(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'):\n",
    "        print(\"Making directory\", f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration')\n",
    "        os.makedirs(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration')                                  \n",
    "  \n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = model.predict(ds_val.batch(512), verbose=0)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)\n",
    "    np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)\n",
    "    np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_nll.npy', opt_temp)\n",
    "\n",
    "    opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)\n",
    "    np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29810af6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "#     if not os.path.exists(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'):\n",
    "#         print(\"Making directory\", f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration')\n",
    "#         os.makedirs(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration')                                  \n",
    "  \n",
    "    \n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = model.predict(ds_val.batch(512), verbose=0)\n",
    "    \n",
    "    opt_temp, opt_weights = temp_scaling.ensemble_temp_scaling_nll(scores, true_y_val, num_classes)\n",
    "    np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_ets_nll.npy', opt_temp)\n",
    "    np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_weights_ets_nll.npy', opt_weights)\n",
    "\n",
    "#     opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)\n",
    "#     np.save(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/softmax_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba245121",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "    \n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = model.predict(ds_val.batch(512), verbose=0)\n",
    "    \n",
    "    pts = temp_scaling.PTSCalibrator(\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=64,\n",
    "    nlayers=2,\n",
    "    n_nodes=32,\n",
    "    length_logits=10,\n",
    "    top_k_logits=5\n",
    ")\n",
    "\n",
    "    pts.tune(logits=scores, labels=pred_y_val)\n",
    "    pts.save(path=f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/calibration_model/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4aafd534",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 2\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 3\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 4\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 5\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 6\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 7\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 8\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 9\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 10\n",
      "18/18 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pmi/separable_variational_f_js'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pmi_output_class_val.npy')\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                            \n",
    "    np.save(f'{exp_name}/pmi_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                                \n",
    "    np.save(f'{exp_name}/pmi_opt_temp_nll.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                                \n",
    "    np.save(f'{exp_name}/pmi_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "faa64dce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "18/18 [==============================] - 0s 8ms/step\n",
      "Run: 2\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 3\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 4\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 5\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 6\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 7\n",
      "18/18 [==============================] - 0s 9ms/step\n",
      "Run: 8\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 9\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Run: 10\n",
      "18/18 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/psi/gaussian'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/psi_output_class_500_projs_val.npy')\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                                 \n",
    "    np.save(f'{exp_name}/psi_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                            \n",
    "    np.save(f'{exp_name}/psi_opt_temp_nll.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                            \n",
    "    np.save(f'{exp_name}/psi_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c477f18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 2\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 3\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Run: 4\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 5\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 6\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Run: 7\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 8\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 9\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 10\n",
      "18/18 [==============================] - 0s 6ms/step\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pvi_class_val.npy')\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                                 \n",
    "    np.save(f'{exp_name}/pvi_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                                          \n",
    "    np.save(f'{exp_name}/pvi_opt_temp_nll.npy', opt_temp)\n",
    "\n",
    "    opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                                          \n",
    "    np.save(f'{exp_name}/pvi_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "81bc332d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run: 1\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 2\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 3\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 4\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 5\n",
      "18/18 [==============================] - 0s 7ms/step\n",
      "Run: 6\n",
      "18/18 [==============================] - 0s 6ms/step\n",
      "Run: 7\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 8\n",
      "18/18 [==============================] - 0s 5ms/step\n",
      "Run: 9\n",
      "18/18 [==============================] - 0s 4ms/step\n",
      "Run: 10\n",
      "18/18 [==============================] - 0s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pvi_class_best_val.npy')\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_aurc(scores, pred_y_val, true_y_val)                                 \n",
    "    np.save(f'{exp_name}/pvi_best_opt_temp_aurc.npy', opt_temp)\n",
    "    \n",
    "    opt_temp = temp_scaling.temp_scaling_nll(scores, true_y_val)                                          \n",
    "    np.save(f'{exp_name}/pvi_best_opt_temp_nll.npy', opt_temp)\n",
    "\n",
    "    opt_temp = temp_scaling.temp_scaling_ece(scores, pred_y_val, true_y_val, 15)                                          \n",
    "    np.save(f'{exp_name}/pvi_best_opt_temp_ece.npy', opt_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97051c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pvi_class_val.npy')\n",
    "    \n",
    "    opt_temp, opt_weights = temp_scaling.ensemble_temp_scaling_nll(scores, true_y_val, num_classes)\n",
    "    np.save(f'{exp_name}/pvi_opt_temp_ets_nll.npy', opt_temp)\n",
    "    np.save(f'{exp_name}/pvi_opt_weights_ets_nll.npy', opt_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d7e217",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for run in range(10):\n",
    "    print(f'Run: {run+1}')\n",
    "    tf.keras.utils.set_random_seed(run+10) # set random seed for Python, NumPy, and TensorFlow\n",
    "    exp_name = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/pvi/training_from_scratch'\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_val = np.argmax(model.predict(ds_val.batch(512), verbose=1), axis=1)\n",
    "    scores = np.load(f'{exp_name}/pvi_class_val.npy')\n",
    "    \n",
    "    opt_temp, opt_weights = temp_scaling.ensemble_temp_scaling_nll(scores, true_y_val, num_classes)\n",
    "    np.save(f'{exp_name}/pvi_opt_temp_ets_nll.npy', opt_temp)\n",
    "    np.save(f'{exp_name}/pvi_opt_weights_ets_nll.npy', opt_weights)\n",
    "    \n",
    "    pts = temp_scaling.PTSCalibrator(\n",
    "    epochs=30,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    batch_size=64,\n",
    "    nlayers=2,\n",
    "    n_nodes=128,\n",
    "    length_logits=10,\n",
    "    top_k_logits=5\n",
    ")\n",
    "\n",
    "    pts.tune(logits=scores, labels=pred_y_val)\n",
    "    pts.save(path=f'{exp_name}/calibration_model/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47f3829",
   "metadata": {},
   "source": [
    "### Failure Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9e0f6b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_confidence_scores(conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name):\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'\n",
    "    metric = conf_method.split('_')[-1] if 'temp_scaling' in conf_method else None\n",
    "    method_key = conf_method.replace(f'_temp_scaling_{metric}', '') if metric else conf_method\n",
    "\n",
    "    if method_key == 'softmax':\n",
    "        if metric:\n",
    "            opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "            return methods.max_softmax_prob(model, ds_test, opt_temp)\n",
    "        else:\n",
    "            return methods.max_softmax_prob(model, ds_test)\n",
    "\n",
    "    elif method_key in ['pmi', 'psi', 'pvi', 'pvi_best']:\n",
    "        if method_key == 'pmi':\n",
    "            exp_path = f'{base_path}/pmi/separable_variational_f_js'\n",
    "            class_file = 'pmi_output_class_test.npy'\n",
    "        elif method_key == 'psi':\n",
    "            exp_path = f'{base_path}/psi/gaussian'\n",
    "            class_file = 'psi_output_class_500_projs_test.npy'\n",
    "        elif method_key == 'pvi':\n",
    "            exp_path = f'{base_path}/pvi/training_from_scratch'\n",
    "            class_file = 'pvi_class_test.npy'\n",
    "        elif method_key == 'pvi_best':\n",
    "            exp_path = f'{base_path}/pvi/training_from_scratch'\n",
    "            class_file = 'pvi_class_best_test.npy'\n",
    "\n",
    "        opt_temp = np.load(f'{exp_path}/{method_key}_opt_temp_{metric}.npy')\n",
    "        scores_class = np.load(f'{exp_path}/{class_file}')\n",
    "        scores_class = np.array([utils.softmax(x / opt_temp) for x in scores_class])\n",
    "        return np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "\n",
    "    elif method_key == 'softmax_margin':\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        return methods.softmax_margin(model, ds_test, opt_temp)\n",
    "\n",
    "    elif method_key == 'max_logits':\n",
    "        return methods.max_logits(model, ds_test)\n",
    "\n",
    "    elif method_key == 'logits_margin':\n",
    "        return methods.logits_margin(model, ds_test)\n",
    "\n",
    "    elif method_key == 'negative_entropy':\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        return methods.negative_entropy(model, ds_test, opt_temp)\n",
    "\n",
    "    elif method_key == 'negative_gini':\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        return methods.negative_gini(model, ds_test, opt_temp)\n",
    "\n",
    "    elif method_key == 'isotonic_regression':\n",
    "        return methods.isotonic_reg(model, ds_val, ds_test, true_y_val)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown confidence method: {conf_method}\")\n",
    "\n",
    "\n",
    "def evaluate_failure_pred(ds_test, true_y_test, conf_method, n_runs=10):\n",
    "    results = {\n",
    "        \"auroc\": [],\n",
    "        \"fpr_at_95tpr\": [],\n",
    "        \"auprc_success\": [],\n",
    "        \"auprc_error\": [],\n",
    "        \"aurc\": [],\n",
    "        \"eaurc\": [],\n",
    "        \"naurc\": []\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        scores_test = get_confidence_scores(conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name)\n",
    "\n",
    "        results[\"auroc\"].append(metrics.compute_auroc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_success\"].append(metrics.compute_auprc_success(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_error\"].append(metrics.compute_auprc_error(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"fpr_at_95tpr\"].append(metrics.compute_fpr_at_95tpr(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"aurc\"].append(metrics.compute_aurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"eaurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"naurc\"].append(metrics.compute_naurc(scores_test, pred_y_test, true_y_test))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4a95b0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: softmax_temp_scaling_aurc\n",
      "AUROC           : 94.99 (1.13)\n",
      "AUPRC (success) : 99.84 (0.05)\n",
      "AUPRC (error)   : 40.84 (2.75)\n",
      "FPR at 95% TPR  : 16.07 (4.52)\n",
      "AURC            : 1.72 (0.51)\n",
      "EAURC           : 1.53 (0.52)\n",
      "NAURC           : 79.10 (27.28)\n",
      "Method: pmi_temp_scaling_aurc\n",
      "AUROC           : 61.97 (0.73)\n",
      "AUPRC (success) : 98.50 (0.05)\n",
      "AUPRC (error)   : 16.61 (1.80)\n",
      "FPR at 95% TPR  : N/A\n",
      "AURC            : 15.04 (0.45)\n",
      "EAURC           : 14.85 (0.45)\n",
      "NAURC           : 762.00 (14.63)\n",
      "Method: psi_temp_scaling_aurc\n",
      "AUROC           : 77.70 (0.98)\n",
      "AUPRC (success) : 99.12 (0.04)\n",
      "AUPRC (error)   : 23.05 (2.09)\n",
      "FPR at 95% TPR  : N/A\n",
      "AURC            : 8.82 (0.43)\n",
      "EAURC           : 8.62 (0.42)\n",
      "NAURC           : 442.53 (19.85)\n",
      "Method: pvi_temp_scaling_aurc\n",
      "AUROC           : 93.02 (5.90)\n",
      "AUPRC (success) : 99.79 (0.26)\n",
      "AUPRC (error)   : 41.60 (4.64)\n",
      "FPR at 95% TPR  : 23.12 (3.27)\n",
      "AURC            : 2.29 (2.60)\n",
      "EAURC           : 2.09 (2.59)\n",
      "NAURC           : 105.11 (126.64)\n",
      "Method: softmax_margin_temp_scaling_aurc\n",
      "AUROC           : 95.14 (1.02)\n",
      "AUPRC (success) : 99.85 (0.05)\n",
      "AUPRC (error)   : 39.44 (1.99)\n",
      "FPR at 95% TPR  : 15.95 (4.42)\n",
      "AURC            : 1.65 (0.47)\n",
      "EAURC           : 1.46 (0.48)\n",
      "NAURC           : 75.49 (25.21)\n",
      "Method: max_logits\n",
      "AUROC           : 90.89 (0.32)\n",
      "AUPRC (success) : 99.78 (0.01)\n",
      "AUPRC (error)   : 28.85 (1.49)\n",
      "FPR at 95% TPR  : 40.67 (1.44)\n",
      "AURC            : 2.32 (0.11)\n",
      "EAURC           : 2.12 (0.10)\n",
      "NAURC           : 108.90 (3.83)\n",
      "Method: logits_margin\n",
      "AUROC           : 96.67 (0.18)\n",
      "AUPRC (success) : 99.93 (0.01)\n",
      "AUPRC (error)   : 39.40 (1.89)\n",
      "FPR at 95% TPR  : 16.87 (1.66)\n",
      "AURC            : 0.91 (0.06)\n",
      "EAURC           : 0.71 (0.05)\n",
      "NAURC           : 36.61 (2.13)\n",
      "Method: negative_entropy_temp_scaling_aurc\n",
      "AUROC           : 96.64 (0.19)\n",
      "AUPRC (success) : 99.93 (0.00)\n",
      "AUPRC (error)   : 40.96 (2.66)\n",
      "FPR at 95% TPR  : 18.12 (5.13)\n",
      "AURC            : 0.91 (0.05)\n",
      "EAURC           : 0.72 (0.05)\n",
      "NAURC           : 36.86 (2.11)\n",
      "Method: negative_gini_temp_scaling_aurc\n",
      "AUROC           : 94.98 (1.12)\n",
      "AUPRC (success) : 99.84 (0.05)\n",
      "AUPRC (error)   : 40.87 (2.80)\n",
      "FPR at 95% TPR  : 16.96 (3.93)\n",
      "AURC            : 1.73 (0.51)\n",
      "EAURC           : 1.53 (0.52)\n",
      "NAURC           : 79.20 (27.18)\n"
     ]
    }
   ],
   "source": [
    "methods_list = ['softmax_temp_scaling_aurc','pmi_temp_scaling_aurc','psi_temp_scaling_aurc','pvi_temp_scaling_aurc',\n",
    "                'softmax_margin_temp_scaling_aurc', 'max_logits', 'logits_margin', 'negative_entropy_temp_scaling_aurc',\n",
    "                'negative_gini_temp_scaling_aurc']\n",
    "for method in methods_list:\n",
    "    print(f'Method: {method}')\n",
    "    results = evaluate_failure_pred(ds_test, true_y_test, conf_method=f'{method}', n_runs=10)\n",
    "    print(f\"AUROC           : {utils.format_ci(results['auroc'], scale=100)}\")\n",
    "    print(f\"AUPRC (success) : {utils.format_ci(results['auprc_success'], scale=100)}\")\n",
    "    print(f\"AUPRC (error)   : {utils.format_ci(results['auprc_error'], scale=100)}\")\n",
    "    print(f\"FPR at 95% TPR  : {utils.format_ci(results['fpr_at_95tpr'], scale=100)}\")\n",
    "    print(f\"AURC            : {utils.format_ci(results['aurc'], scale=1000)}\")\n",
    "    print(f\"EAURC           : {utils.format_ci(results['eaurc'], scale=1000)}\")\n",
    "    print(f\"NAURC           : {utils.format_ci(results['naurc'], scale=1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210f8713",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ets(logits, opt_temp, opt_weights, n_class):\n",
    "    p1 = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    scaled_logits = logits / opt_temp\n",
    "    p0 = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits), axis=1, keepdims=True)\n",
    "    p2 = np.ones_like(p0) / n_class\n",
    "    w = opt_weights / np.sum(opt_weights)  # just in case\n",
    "    calibrated_probs = w[0] * p0 + w[1] * p1 + w[2] * p2\n",
    "    return calibrated_probs\n",
    "\n",
    "\n",
    "method = 'softmax ETS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"auroc\": [],\n",
    "        \"fpr_at_95tpr\": [],\n",
    "        \"auprc_success\": [],\n",
    "        \"auprc_error\": [],\n",
    "        \"aurc\": [],\n",
    "        \"eaurc\": []\n",
    "    }\n",
    "for run in range(10):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        \n",
    "        logits = model.predict(ds_test.batch(512), verbose=0)\n",
    "        \n",
    "        base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_ets_nll.npy')\n",
    "        opt_weights = np.load(f'{base_path}/softmax_opt_weights_ets_nll.npy')\n",
    "        \n",
    "        scores_class = apply_ets(logits,opt_temp,opt_weights,num_classes)\n",
    "        scores_test = np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "        \n",
    "        results[\"auroc\"].append(metrics.compute_auroc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_success\"].append(metrics.compute_auprc_success(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_error\"].append(metrics.compute_auprc_error(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"fpr_at_95tpr\"].append(metrics.compute_fpr_at_95tpr(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"aurc\"].append(metrics.compute_aurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"eaurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "        \n",
    "print(f\"AUROC           : {utils.format_ci(results['auroc'], scale=100)}\")\n",
    "print(f\"AUPRC (success) : {utils.format_ci(results['auprc_success'], scale=100)}\")\n",
    "print(f\"AUPRC (error)   : {utils.format_ci(results['auprc_error'], scale=100)}\")\n",
    "print(f\"FPR at 95% TPR  : {utils.format_ci(results['fpr_at_95tpr'], scale=100)}\")\n",
    "print(f\"AURC            : {utils.format_ci(results['aurc'], scale=1000)}\")\n",
    "print(f\"EAURC           : {utils.format_ci(results['eaurc'], scale=1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e16ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ets(logits, opt_temp, opt_weights, n_class):\n",
    "    p1 = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    scaled_logits = logits / opt_temp\n",
    "    p0 = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits), axis=1, keepdims=True)\n",
    "    p2 = np.ones_like(p0) / n_class\n",
    "    w = opt_weights / np.sum(opt_weights)  # just in case\n",
    "    calibrated_probs = w[0] * p0 + w[1] * p1 + w[2] * p2\n",
    "    return calibrated_probs\n",
    "\n",
    "\n",
    "method = 'PVI ETS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"auroc\": [],\n",
    "        \"fpr_at_95tpr\": [],\n",
    "        \"auprc_success\": [],\n",
    "        \"auprc_error\": [],\n",
    "        \"aurc\": [],\n",
    "        \"eaurc\": []\n",
    "    }\n",
    "for run in range(10):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        \n",
    "        base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "        pvi =  np.load(f'{base_path}/pvi/training_from_scratch/pvi_class_test.npy')\n",
    "        opt_temp = np.load(f'{base_path}/pvi/training_from_scratch/pvi_opt_temp_ets_nll.npy')\n",
    "        opt_weights = np.load(f'{base_path}/pvi/training_from_scratch/pvi_opt_weights_ets_nll.npy')\n",
    "        \n",
    "        scores_class = apply_ets(pvi,opt_temp,opt_weights,num_classes)\n",
    "        scores_test = np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "        \n",
    "        results[\"auroc\"].append(metrics.compute_auroc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_success\"].append(metrics.compute_auprc_success(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_error\"].append(metrics.compute_auprc_error(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"fpr_at_95tpr\"].append(metrics.compute_fpr_at_95tpr(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"aurc\"].append(metrics.compute_aurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"eaurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "        \n",
    "print(f\"AUROC           : {utils.format_ci(results['auroc'], scale=100)}\")\n",
    "print(f\"AUPRC (success) : {utils.format_ci(results['auprc_success'], scale=100)}\")\n",
    "print(f\"AUPRC (error)   : {utils.format_ci(results['auprc_error'], scale=100)}\")\n",
    "print(f\"FPR at 95% TPR  : {utils.format_ci(results['fpr_at_95tpr'], scale=100)}\")\n",
    "print(f\"AURC            : {utils.format_ci(results['aurc'], scale=1000)}\")\n",
    "print(f\"EAURC           : {utils.format_ci(results['eaurc'], scale=1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01ee9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'softmax PTS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"auroc\": [],\n",
    "        \"fpr_at_95tpr\": [],\n",
    "        \"auprc_success\": [],\n",
    "        \"auprc_error\": [],\n",
    "        \"aurc\": [],\n",
    "        \"eaurc\": []\n",
    "    }\n",
    "for run in range(10):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        \n",
    "        logits = model.predict(ds_test.batch(512), verbose=0)\n",
    "        \n",
    "        base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_ets_nll.npy')\n",
    "        opt_weights = np.load(f'{base_path}/softmax_opt_weights_ets_nll.npy')\n",
    "        \n",
    "        pts_loaded = temp_scaling.PTSCalibrator(\n",
    "        epochs=0,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        batch_size=64,\n",
    "        nlayers=2,\n",
    "        n_nodes=32,\n",
    "        length_logits=10,\n",
    "        top_k_logits=5\n",
    "    )\n",
    "        pts_loaded.load(path=f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/calibration_model/')\n",
    "        scores_class = pts_loaded.calibrate(logits)\n",
    "        scores_test = np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "        \n",
    "        results[\"auroc\"].append(metrics.compute_auroc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_success\"].append(metrics.compute_auprc_success(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_error\"].append(metrics.compute_auprc_error(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"fpr_at_95tpr\"].append(metrics.compute_fpr_at_95tpr(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"aurc\"].append(metrics.compute_aurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"eaurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "        \n",
    "print(f\"AUROC           : {utils.format_ci(results['auroc'], scale=100)}\")\n",
    "print(f\"AUPRC (success) : {utils.format_ci(results['auprc_success'], scale=100)}\")\n",
    "print(f\"AUPRC (error)   : {utils.format_ci(results['auprc_error'], scale=100)}\")\n",
    "print(f\"FPR at 95% TPR  : {utils.format_ci(results['fpr_at_95tpr'], scale=100)}\")\n",
    "print(f\"AURC            : {utils.format_ci(results['aurc'], scale=1000)}\")\n",
    "print(f\"EAURC           : {utils.format_ci(results['eaurc'], scale=1000)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c7251b",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'PVI PTS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"auroc\": [],\n",
    "        \"fpr_at_95tpr\": [],\n",
    "        \"auprc_success\": [],\n",
    "        \"auprc_error\": [],\n",
    "        \"aurc\": [],\n",
    "        \"eaurc\": []\n",
    "    }\n",
    "for run in range(10):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        \n",
    "        base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "        pvi =  np.load(f'{base_path}/pvi/training_from_scratch/pvi_class_test.npy')\n",
    "        \n",
    "        pts_loaded = temp_scaling.PTSCalibrator(\n",
    "        epochs=0,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        batch_size=64,\n",
    "        nlayers=2,\n",
    "        n_nodes=32,\n",
    "        length_logits=10,\n",
    "        top_k_logits=5\n",
    "    )\n",
    "        pts_loaded.load(path=f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/calibration_model/')\n",
    "        scores_class = pts_loaded.calibrate(pvi)\n",
    "        scores_test = np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "        \n",
    "        results[\"auroc\"].append(metrics.compute_auroc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_success\"].append(metrics.compute_auprc_success(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"auprc_error\"].append(metrics.compute_auprc_error(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"fpr_at_95tpr\"].append(metrics.compute_fpr_at_95tpr(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"aurc\"].append(metrics.compute_aurc(scores_test, pred_y_test, true_y_test))\n",
    "        results[\"eaurc\"].append(metrics.compute_eaurc(scores_test, pred_y_test, true_y_test))\n",
    "        \n",
    "print(f\"AUROC           : {utils.format_ci(results['auroc'], scale=100)}\")\n",
    "print(f\"AUPRC (success) : {utils.format_ci(results['auprc_success'], scale=100)}\")\n",
    "print(f\"AUPRC (error)   : {utils.format_ci(results['auprc_error'], scale=100)}\")\n",
    "print(f\"FPR at 95% TPR  : {utils.format_ci(results['fpr_at_95tpr'], scale=100)}\")\n",
    "print(f\"AURC            : {utils.format_ci(results['aurc'], scale=1000)}\")\n",
    "print(f\"EAURC           : {utils.format_ci(results['eaurc'], scale=1000)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5999f32",
   "metadata": {},
   "source": [
    "### Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d6c99bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_scores_for_calibration(conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name):\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration'\n",
    "\n",
    "    def softmax_scaled(scores, temp=1.0):\n",
    "        return np.array([utils.softmax(x / temp) for x in scores])\n",
    "\n",
    "    if conf_method == 'softmax':\n",
    "        scores_class = methods.softmax_prob(model, ds_test)\n",
    "        scores_test = methods.max_softmax_prob(model, ds_test)\n",
    "        return scores_class, scores_test\n",
    "\n",
    "    if conf_method.startswith('softmax_temp_scaling'):\n",
    "        metric = conf_method.split('_')[-1]\n",
    "        opt_temp = np.load(f'{base_path}/softmax_opt_temp_{metric}.npy')\n",
    "        scores_class = methods.softmax_prob(model, ds_test, opt_temp)\n",
    "        scores_test = methods.max_softmax_prob(model, ds_test, opt_temp)\n",
    "        return scores_class, scores_test\n",
    "\n",
    "    if conf_method in ['pmi', 'psi', 'pvi', 'pvi_best']:\n",
    "        method = conf_method\n",
    "        metric = None\n",
    "        temp = 1.0\n",
    "    elif conf_method.startswith(('pmi_temp_scaling', 'psi_temp_scaling', 'pvi_temp_scaling', 'pvi_best_temp_scaling')):\n",
    "        parts = conf_method.split('_')\n",
    "        method = '_'.join(parts[:2]) if 'best' in parts else parts[0]\n",
    "        metric = parts[-1]\n",
    "        method_dir = {\n",
    "            'pmi': 'pmi/separable_variational_f_js',\n",
    "            'psi': 'psi/gaussian',\n",
    "            'pvi': 'pvi/training_from_scratch',\n",
    "            'pvi_best': 'pvi/training_from_scratch'\n",
    "        }[method]\n",
    "        temp = float(np.load(f'{base_path}/{method_dir}/{method}_opt_temp_{metric}.npy'))\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown confidence method: {conf_method}\")\n",
    "\n",
    "    method_paths = {\n",
    "        'pmi': (f'{base_path}/pmi/separable_variational_f_js', 'pmi_output_class_test.npy'),\n",
    "        'psi': (f'{base_path}/psi/gaussian', 'psi_output_class_500_projs_test.npy'),\n",
    "        'pvi': (f'{base_path}/pvi/training_from_scratch', 'pvi_class_test.npy'),\n",
    "        'pvi_best': (f'{base_path}/pvi/training_from_scratch', 'pvi_class_best_test.npy'),\n",
    "    }\n",
    "\n",
    "    method_path, class_file = method_paths[method]\n",
    "    scores_class = np.load(f'{method_path}/{class_file}')\n",
    "    scores_class = softmax_scaled(scores_class, temp)\n",
    "    scores_test = np.array([score[pred] for score, pred in zip(scores_class, pred_y_test)])\n",
    "    return scores_class, scores_test\n",
    "\n",
    "def evaluate_calibration(ds_test, true_y_test, conf_method, n_runs=10):\n",
    "    results = {\n",
    "        \"ece\": [],\n",
    "        \"cc_ece\": [],\n",
    "        \"mce\": [],\n",
    "        \"ace\": [],\n",
    "        \"sce\": [],\n",
    "        \"ada_ece\": [],\n",
    "        \"ada_sce\": [],\n",
    "        \"cc_ada_ece\": [],\n",
    "        \"cc_ada_sce\": [],\n",
    "        \"cc_ada_sce_rms\": [],\n",
    "        \"cw_ece\": [],\n",
    "        \"cw_sce\": [],\n",
    "        \"cw_ada_ece\": [],\n",
    "        \"cw_ada_sce\": [],\n",
    "        \"cw_ada_ece_rms\": [],\n",
    "        \"cw_ada_sce_rms\": [],\n",
    "        \"nll\": [],\n",
    "        \"bs\": [],\n",
    "        \"sharpness\": [],\n",
    "    }\n",
    "\n",
    "    for run in range(n_runs):\n",
    "        tf.keras.utils.set_random_seed(run + 10)\n",
    "        model = create_model()\n",
    "        model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "        pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "        scores_class, scores_test = get_scores_for_calibration(\n",
    "            conf_method, model, ds_test, pred_y_test, run, model_name, dataset_name\n",
    "        )\n",
    "\n",
    "        results[\"ece\"].append(metrics.compute_ece(scores_test, pred_y_test, true_y_test, 15))\n",
    "        results[\"cc_ece\"].append(metrics.compute_cc_ece(scores_test, pred_y_test, true_y_test, 15))\n",
    "        results[\"mce\"].append(metrics.compute_mce(scores_test, pred_y_test, true_y_test, 15))\n",
    "        results[\"ace\"].append(metrics.compute_ace(scores_test, pred_y_test, true_y_test, 15))\n",
    "        results[\"sce\"].append(metrics.compute_sce(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"ada_ece\"].append(metrics.compute_adaece(scores_test, pred_y_test, true_y_test, 15))\n",
    "        results[\"ada_sce\"].append(metrics.compute_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cc_ada_ece\"].append(metrics.compute_cc_adaece(scores_test, pred_y_test, true_y_test, 15))\n",
    "        results[\"cc_ada_sce\"].append(metrics.compute_cc_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cc_ada_sce_rms\"].append(metrics.compute_cc_adasce_rms(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cw_ece\"].append(metrics.compute_cw_ece(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cw_sce\"].append(metrics.compute_cw_sce(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cw_ada_ece\"].append(metrics.compute_cw_adaece(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cw_ada_sce\"].append(metrics.compute_cw_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cw_ada_ece_rms\"].append(metrics.compute_cw_adaece_rms(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"cw_ada_sce_rms\"].append(metrics.compute_cw_adaece_rms(scores_class, true_y_test, num_classes, 15))\n",
    "        results[\"nll\"].append(metrics.compute_nll(scores_class, true_y_test, num_classes))\n",
    "        results[\"bs\"].append(metrics.compute_brier_score(scores_class, true_y_test, num_classes))\n",
    "        results[\"sharpness\"].append(metrics.compute_sharpness(scores_class))\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47fa25d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: softmax\n",
      "ECE:            1.26 (0.08)\n",
      "CC-ECE:         1.46 (0.09)\n",
      "MCE:            0.78 (0.08)\n",
      "ACE:            17.37 (1.82)\n",
      "SCE:            0.30 (0.02)\n",
      "Ada-ECE:        1.22 (0.09)\n",
      "Ada-SCE:        0.16 (0.01)\n",
      "CC-Ada-ECE:     1.23 (0.09)\n",
      "CC-Ada-SCE:     0.15 (0.01)\n",
      "CC-Ada-SCE-RMS: 1.79 (0.11)\n",
      "CW-ECE:         0.30 (0.02)\n",
      "CW-SCE:         0.30 (0.02)\n",
      "CW-Ada-ECE:     0.08 (0.01)\n",
      "CW-Ada-SCE:     0.08 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.24 (0.04)\n",
      "CW-Ada-SCE-RMS: 0.24 (0.04)\n",
      "NLL:            9.19 (0.65)\n",
      "Brier Score:    3.26 (0.09)\n",
      "Sharpness:      1.97 (0.21)\n",
      "Method: pmi\n",
      "ECE:            0.49 (0.12)\n",
      "CC-ECE:         1.01 (0.08)\n",
      "MCE:            0.21 (0.09)\n",
      "ACE:            8.11 (1.36)\n",
      "SCE:            0.19 (0.01)\n",
      "Ada-ECE:        0.37 (0.14)\n",
      "Ada-SCE:        0.11 (0.01)\n",
      "CC-Ada-ECE:     0.60 (0.08)\n",
      "CC-Ada-SCE:     0.25 (0.02)\n",
      "CC-Ada-SCE-RMS: 2.76 (0.15)\n",
      "CW-ECE:         0.19 (0.01)\n",
      "CW-SCE:         0.19 (0.01)\n",
      "CW-Ada-ECE:     0.07 (0.01)\n",
      "CW-Ada-SCE:     0.07 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.21 (0.03)\n",
      "CW-Ada-SCE-RMS: 0.21 (0.03)\n",
      "NLL:            6.47 (0.27)\n",
      "Brier Score:    2.99 (0.08)\n",
      "Sharpness:      5.06 (0.84)\n",
      "Method: psi\n",
      "ECE:            27.12 (1.07)\n",
      "CC-ECE:         27.08 (1.06)\n",
      "MCE:            4.45 (0.14)\n",
      "ACE:            34.34 (0.81)\n",
      "SCE:            5.19 (0.19)\n",
      "Ada-ECE:        27.12 (1.07)\n",
      "Ada-SCE:        4.76 (0.17)\n",
      "CC-Ada-ECE:     27.04 (1.07)\n",
      "CC-Ada-SCE:     2.93 (0.10)\n",
      "CC-Ada-SCE-RMS: 10.62 (0.29)\n",
      "CW-ECE:         5.19 (0.19)\n",
      "CW-SCE:         5.19 (0.19)\n",
      "CW-Ada-ECE:     4.49 (0.19)\n",
      "CW-Ada-SCE:     4.49 (0.19)\n",
      "CW-Ada-ECE-RMS: 7.32 (0.30)\n",
      "CW-Ada-SCE-RMS: 7.32 (0.30)\n",
      "NLL:            39.23 (1.61)\n",
      "Brier Score:    14.55 (0.76)\n",
      "Sharpness:      102.21 (2.87)\n",
      "Method: pvi\n",
      "ECE:            0.58 (0.08)\n",
      "CC-ECE:         1.22 (0.08)\n",
      "MCE:            0.12 (0.03)\n",
      "ACE:            11.97 (1.48)\n",
      "SCE:            0.18 (0.01)\n",
      "Ada-ECE:        0.58 (0.10)\n",
      "Ada-SCE:        0.12 (0.01)\n",
      "CC-Ada-ECE:     0.83 (0.09)\n",
      "CC-Ada-SCE:     0.29 (0.01)\n",
      "CC-Ada-SCE-RMS: 3.01 (0.07)\n",
      "CW-ECE:         0.18 (0.01)\n",
      "CW-SCE:         0.18 (0.01)\n",
      "CW-Ada-ECE:     0.09 (0.01)\n",
      "CW-Ada-SCE:     0.09 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.30 (0.04)\n",
      "CW-Ada-SCE-RMS: 0.30 (0.04)\n",
      "NLL:            6.47 (0.18)\n",
      "Brier Score:    3.02 (0.07)\n",
      "Sharpness:      6.55 (0.36)\n",
      "Method: pvi_best\n",
      "ECE:            0.62 (0.04)\n",
      "CC-ECE:         1.28 (0.06)\n",
      "MCE:            0.15 (0.02)\n",
      "ACE:            11.03 (1.68)\n",
      "SCE:            0.21 (0.01)\n",
      "Ada-ECE:        0.62 (0.06)\n",
      "Ada-SCE:        0.13 (0.01)\n",
      "CC-Ada-ECE:     0.87 (0.05)\n",
      "CC-Ada-SCE:     0.29 (0.01)\n",
      "CC-Ada-SCE-RMS: 3.03 (0.07)\n",
      "CW-ECE:         0.21 (0.01)\n",
      "CW-SCE:         0.21 (0.01)\n",
      "CW-Ada-ECE:     0.10 (0.01)\n",
      "CW-Ada-SCE:     0.10 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.31 (0.03)\n",
      "CW-Ada-SCE-RMS: 0.31 (0.03)\n",
      "NLL:            6.26 (0.02)\n",
      "Brier Score:    2.94 (0.00)\n",
      "Sharpness:      6.88 (0.39)\n",
      "Method: softmax_temp_scaling_nll\n",
      "ECE:            0.34 (0.07)\n",
      "CC-ECE:         1.03 (0.05)\n",
      "MCE:            0.10 (0.04)\n",
      "ACE:            9.46 (2.28)\n",
      "SCE:            0.18 (0.01)\n",
      "Ada-ECE:        0.21 (0.06)\n",
      "Ada-SCE:        0.12 (0.01)\n",
      "CC-Ada-ECE:     0.71 (0.07)\n",
      "CC-Ada-SCE:     0.29 (0.01)\n",
      "CC-Ada-SCE-RMS: 3.01 (0.07)\n",
      "CW-ECE:         0.18 (0.01)\n",
      "CW-SCE:         0.18 (0.01)\n",
      "CW-Ada-ECE:     0.09 (0.01)\n",
      "CW-Ada-SCE:     0.09 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.30 (0.04)\n",
      "CW-Ada-SCE-RMS: 0.30 (0.04)\n",
      "NLL:            6.45 (0.18)\n",
      "Brier Score:    3.02 (0.07)\n",
      "Sharpness:      6.50 (0.35)\n",
      "Method: pmi_temp_scaling_nll\n",
      "ECE:            0.31 (0.07)\n",
      "CC-ECE:         0.95 (0.05)\n",
      "MCE:            0.08 (0.02)\n",
      "ACE:            7.50 (1.52)\n",
      "SCE:            0.17 (0.01)\n",
      "Ada-ECE:        0.14 (0.03)\n",
      "Ada-SCE:        0.10 (0.01)\n",
      "CC-Ada-ECE:     0.56 (0.04)\n",
      "CC-Ada-SCE:     0.28 (0.01)\n",
      "CC-Ada-SCE-RMS: 3.02 (0.06)\n",
      "CW-ECE:         0.17 (0.01)\n",
      "CW-SCE:         0.17 (0.01)\n",
      "CW-Ada-ECE:     0.07 (0.01)\n",
      "CW-Ada-SCE:     0.07 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.22 (0.03)\n",
      "CW-Ada-SCE-RMS: 0.22 (0.03)\n",
      "NLL:            6.32 (0.18)\n",
      "Brier Score:    2.97 (0.08)\n",
      "Sharpness:      6.56 (0.14)\n",
      "Method: psi_temp_scaling_nll\n",
      "ECE:            1.75 (0.16)\n",
      "CC-ECE:         2.14 (0.14)\n",
      "MCE:            0.28 (0.04)\n",
      "ACE:            23.26 (1.43)\n",
      "SCE:            0.30 (0.02)\n",
      "Ada-ECE:        1.78 (0.17)\n",
      "Ada-SCE:        0.22 (0.02)\n",
      "CC-Ada-ECE:     1.99 (0.17)\n",
      "CC-Ada-SCE:     0.41 (0.02)\n",
      "CC-Ada-SCE-RMS: 3.74 (0.09)\n",
      "CW-ECE:         0.30 (0.02)\n",
      "CW-SCE:         0.30 (0.02)\n",
      "CW-Ada-ECE:     0.18 (0.01)\n",
      "CW-Ada-SCE:     0.18 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.50 (0.04)\n",
      "CW-Ada-SCE-RMS: 0.50 (0.04)\n",
      "NLL:            9.56 (0.37)\n",
      "Brier Score:    3.99 (0.13)\n",
      "Sharpness:      10.37 (0.41)\n",
      "Method: pvi_temp_scaling_nll\n",
      "ECE:            0.59 (0.08)\n",
      "CC-ECE:         1.23 (0.07)\n",
      "MCE:            0.13 (0.03)\n",
      "ACE:            11.63 (1.81)\n",
      "SCE:            0.18 (0.01)\n",
      "Ada-ECE:        0.62 (0.07)\n",
      "Ada-SCE:        0.12 (0.01)\n",
      "CC-Ada-ECE:     0.85 (0.07)\n",
      "CC-Ada-SCE:     0.29 (0.01)\n",
      "CC-Ada-SCE-RMS: 3.05 (0.05)\n",
      "CW-ECE:         0.18 (0.01)\n",
      "CW-SCE:         0.18 (0.01)\n",
      "CW-Ada-ECE:     0.10 (0.01)\n",
      "CW-Ada-SCE:     0.10 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.31 (0.04)\n",
      "CW-Ada-SCE-RMS: 0.31 (0.04)\n",
      "NLL:            6.47 (0.18)\n",
      "Brier Score:    3.02 (0.07)\n",
      "Sharpness:      6.78 (0.16)\n",
      "Method: pvi_best_temp_scaling_nll\n",
      "ECE:            0.62 (0.04)\n",
      "CC-ECE:         1.28 (0.05)\n",
      "MCE:            0.15 (0.02)\n",
      "ACE:            10.80 (1.40)\n",
      "SCE:            0.21 (0.01)\n",
      "Ada-ECE:        0.63 (0.04)\n",
      "Ada-SCE:        0.13 (0.01)\n",
      "CC-Ada-ECE:     0.88 (0.03)\n",
      "CC-Ada-SCE:     0.29 (0.00)\n",
      "CC-Ada-SCE-RMS: 3.02 (0.02)\n",
      "CW-ECE:         0.21 (0.01)\n",
      "CW-SCE:         0.21 (0.01)\n",
      "CW-Ada-ECE:     0.10 (0.01)\n",
      "CW-Ada-SCE:     0.10 (0.01)\n",
      "CW-Ada-ECE-RMS: 0.31 (0.02)\n",
      "CW-Ada-SCE-RMS: 0.31 (0.02)\n",
      "NLL:            6.26 (0.01)\n",
      "Brier Score:    2.94 (0.00)\n",
      "Sharpness:      6.97 (0.15)\n"
     ]
    }
   ],
   "source": [
    "methods_list = ['softmax','pmi','psi','pvi','pvi_best',\n",
    "                'softmax_temp_scaling_nll','pmi_temp_scaling_nll','psi_temp_scaling_nll','pvi_temp_scaling_nll','pvi_best_temp_scaling_nll']\n",
    "for method in methods_list:\n",
    "    print(f'Method: {method}')\n",
    "    results = evaluate_calibration(ds_test, true_y_test, conf_method=f'{method}', n_runs=10)\n",
    "    print(f\"ECE:            {utils.format_ci(results['ece'], scale=100)}\")\n",
    "    print(f\"CC-ECE:         {utils.format_ci(results['cc_ece'], scale=100)}\")\n",
    "    print(f\"MCE:            {utils.format_ci(results['mce'], scale=100)}\")\n",
    "    print(f\"ACE:            {utils.format_ci(results['ace'], scale=100)}\")\n",
    "    print(f\"SCE:            {utils.format_ci(results['sce'], scale=100)}\")\n",
    "    print(f\"Ada-ECE:        {utils.format_ci(results['ada_ece'], scale=100)}\")\n",
    "    print(f\"Ada-SCE:        {utils.format_ci(results['ada_sce'], scale=100)}\")\n",
    "    print(f\"CC-Ada-ECE:     {utils.format_ci(results['cc_ada_ece'], scale=100)}\")\n",
    "    print(f\"CC-Ada-SCE:     {utils.format_ci(results['cc_ada_sce'], scale=100)}\")\n",
    "    print(f\"CC-Ada-SCE-RMS: {utils.format_ci(results['cc_ada_sce_rms'], scale=100)}\")\n",
    "    print(f\"CW-ECE:         {utils.format_ci(results['cw_ece'], scale=100)}\")\n",
    "    print(f\"CW-SCE:         {utils.format_ci(results['cw_sce'], scale=100)}\")\n",
    "    print(f\"CW-Ada-ECE:     {utils.format_ci(results['cw_ada_ece'], scale=100)}\")\n",
    "    print(f\"CW-Ada-SCE:     {utils.format_ci(results['cw_ada_sce'], scale=100)}\")\n",
    "    print(f\"CW-Ada-ECE-RMS: {utils.format_ci(results['cw_ada_ece_rms'], scale=100)}\")\n",
    "    print(f\"CW-Ada-SCE-RMS: {utils.format_ci(results['cw_ada_sce_rms'], scale=100)}\")\n",
    "    print(f\"NLL:            {utils.format_ci(results['nll'], scale=100)}\")\n",
    "    print(f\"Brier Score:    {utils.format_ci(results['bs'], scale=100)}\")\n",
    "    print(f\"Sharpness:      {utils.format_ci(results['sharpness'], scale=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf689e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ets(logits, opt_temp, opt_weights, n_class):\n",
    "    p1 = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    scaled_logits = logits / opt_temp\n",
    "    p0 = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits), axis=1, keepdims=True)\n",
    "    p2 = np.ones_like(p0) / n_class\n",
    "    w = opt_weights / np.sum(opt_weights)  # just in case\n",
    "    calibrated_probs = w[0] * p0 + w[1] * p1 + w[2] * p2\n",
    "    return calibrated_probs\n",
    "\n",
    "\n",
    "method = 'softmax ETS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"sce\": [],\n",
    "        \"ada_sce\": [],\n",
    "        \"cc_ada_sce\": [],\n",
    "        \"cc_ada_sce_rms\": [],\n",
    "        \"nll\": [],\n",
    "        \"bs\": [],\n",
    "    }\n",
    "for run in range(10):\n",
    "    tf.keras.utils.set_random_seed(run + 10)\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "\n",
    "    logits = model.predict(ds_test.batch(512), verbose=0)\n",
    "\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "    opt_temp = np.load(f'{base_path}/softmax_opt_temp_ets_nll.npy')\n",
    "    opt_weights = np.load(f'{base_path}/softmax_opt_weights_ets_nll.npy')\n",
    "\n",
    "    scores_class = apply_ets(logits,opt_temp,opt_weights,num_classes)\n",
    "\n",
    "    results[\"sce\"].append(metrics.compute_sce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"ada_sce\"].append(metrics.compute_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce\"].append(metrics.compute_cc_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce_rms\"].append(metrics.compute_cc_adasce_rms(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"nll\"].append(metrics.compute_nll(scores_class, true_y_test, num_classes))\n",
    "    results[\"bs\"].append(metrics.compute_brier_score(scores_class, true_y_test, num_classes))\n",
    "        \n",
    "print(f\"SCE:            {utils.format_ci(results['sce'], scale=100)}\")\n",
    "print(f\"Ada-SCE:        {utils.format_ci(results['ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE:     {utils.format_ci(results['cc_ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE-RMS: {utils.format_ci(results['cc_ada_sce_rms'], scale=100)}\")\n",
    "print(f\"NLL:            {utils.format_ci(results['nll'], scale=100)}\")\n",
    "print(f\"Brier Score:    {utils.format_ci(results['bs'], scale=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f7177a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ets(logits, opt_temp, opt_weights, n_class):\n",
    "    p1 = np.exp(logits) / np.sum(np.exp(logits), axis=1, keepdims=True)\n",
    "    scaled_logits = logits / opt_temp\n",
    "    p0 = np.exp(scaled_logits) / np.sum(np.exp(scaled_logits), axis=1, keepdims=True)\n",
    "    p2 = np.ones_like(p0) / n_class\n",
    "    w = opt_weights / np.sum(opt_weights)  # just in case\n",
    "    calibrated_probs = w[0] * p0 + w[1] * p1 + w[2] * p2\n",
    "    return calibrated_probs\n",
    "\n",
    "\n",
    "method = 'PVI ETS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"sce\": [],\n",
    "        \"ada_sce\": [],\n",
    "        \"cc_ada_sce\": [],\n",
    "        \"cc_ada_sce_rms\": [],\n",
    "        \"nll\": [],\n",
    "        \"bs\": [],\n",
    "    }\n",
    "for run in range(10):\n",
    "    tf.keras.utils.set_random_seed(run + 10)\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "    pvi =  np.load(f'{base_path}/pvi/training_from_scratch/pvi_class_test.npy')\n",
    "    opt_temp = np.load(f'{base_path}/pvi/training_from_scratch/pvi_opt_temp_ets_nll.npy')\n",
    "    opt_weights = np.load(f'{base_path}/pvi/training_from_scratch/pvi_opt_weights_ets_nll.npy')\n",
    "\n",
    "    scores_class = apply_ets(pvi,opt_temp,opt_weights,num_classes)\n",
    "\n",
    "    results[\"sce\"].append(metrics.compute_sce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"ada_sce\"].append(metrics.compute_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce\"].append(metrics.compute_cc_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce_rms\"].append(metrics.compute_cc_adasce_rms(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"nll\"].append(metrics.compute_nll(scores_class, true_y_test, num_classes))\n",
    "    results[\"bs\"].append(metrics.compute_brier_score(scores_class, true_y_test, num_classes))\n",
    "        \n",
    "print(f\"SCE:            {utils.format_ci(results['sce'], scale=100)}\")\n",
    "print(f\"Ada-SCE:        {utils.format_ci(results['ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE:     {utils.format_ci(results['cc_ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE-RMS: {utils.format_ci(results['cc_ada_sce_rms'], scale=100)}\")\n",
    "print(f\"NLL:            {utils.format_ci(results['nll'], scale=100)}\")\n",
    "print(f\"Brier Score:    {utils.format_ci(results['bs'], scale=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e568c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'softmax ETS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"sce\": [],\n",
    "        \"ada_sce\": [],\n",
    "        \"cc_ada_sce\": [],\n",
    "        \"cc_ada_sce_rms\": [],\n",
    "        \"nll\": [],\n",
    "        \"bs\": [],\n",
    "    }\n",
    "for run in range(10):\n",
    "    tf.keras.utils.set_random_seed(run + 10)\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "\n",
    "    logits = model.predict(ds_test.batch(512), verbose=0)\n",
    "\n",
    "    pts_loaded = temp_scaling.PTSCalibrator(\n",
    "        epochs=0,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        batch_size=64,\n",
    "        nlayers=2,\n",
    "        n_nodes=32,\n",
    "        length_logits=10,\n",
    "        top_k_logits=5\n",
    "    )\n",
    "    pts_loaded.load(path=f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/calibration_model/')\n",
    "    scores_class = pts_loaded.calibrate(logits)\n",
    "\n",
    "    results[\"sce\"].append(metrics.compute_sce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"ada_sce\"].append(metrics.compute_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce\"].append(metrics.compute_cc_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce_rms\"].append(metrics.compute_cc_adasce_rms(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"nll\"].append(metrics.compute_nll(scores_class, true_y_test, num_classes))\n",
    "    results[\"bs\"].append(metrics.compute_brier_score(scores_class, true_y_test, num_classes))\n",
    "        \n",
    "print(f\"SCE:            {utils.format_ci(results['sce'], scale=100)}\")\n",
    "print(f\"Ada-SCE:        {utils.format_ci(results['ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE:     {utils.format_ci(results['cc_ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE-RMS: {utils.format_ci(results['cc_ada_sce_rms'], scale=100)}\")\n",
    "print(f\"NLL:            {utils.format_ci(results['nll'], scale=100)}\")\n",
    "print(f\"Brier Score:    {utils.format_ci(results['bs'], scale=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982660f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "method = 'PVI PTS'\n",
    "print(f'Method: {method}')\n",
    "results = {\n",
    "        \"sce\": [],\n",
    "        \"ada_sce\": [],\n",
    "        \"cc_ada_sce\": [],\n",
    "        \"cc_ada_sce_rms\": [],\n",
    "        \"nll\": [],\n",
    "        \"bs\": [],\n",
    "    }\n",
    "for run in range(10):\n",
    "    tf.keras.utils.set_random_seed(run + 10)\n",
    "    model = create_model()\n",
    "    model.load_weights(f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/saved_models/trained_weights.h5')\n",
    "\n",
    "    pred_y_test = np.argmax(model.predict(ds_test.batch(256), verbose=0), axis=1)\n",
    "    base_path = f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/'\n",
    "    pvi =  np.load(f'{base_path}/pvi/training_from_scratch/pvi_class_test.npy')\n",
    "\n",
    "    pts_loaded = temp_scaling.PTSCalibrator(\n",
    "        epochs=0,\n",
    "        lr=1e-3,\n",
    "        weight_decay=1e-4,\n",
    "        batch_size=64,\n",
    "        nlayers=2,\n",
    "        n_nodes=32,\n",
    "        length_logits=10,\n",
    "        top_k_logits=5\n",
    "    )\n",
    "    pts_loaded.load(path=f'../results/PI_Explainability/{model_name}_{dataset_name}/run_{run+1}/calibration/calibration_model/')\n",
    "    scores_class = pts_loaded.calibrate(pvi)\n",
    "\n",
    "    results[\"sce\"].append(metrics.compute_sce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"ada_sce\"].append(metrics.compute_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce\"].append(metrics.compute_cc_adasce(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"cc_ada_sce_rms\"].append(metrics.compute_cc_adasce_rms(scores_class, true_y_test, num_classes, 15))\n",
    "    results[\"nll\"].append(metrics.compute_nll(scores_class, true_y_test, num_classes))\n",
    "    results[\"bs\"].append(metrics.compute_brier_score(scores_class, true_y_test, num_classes))\n",
    "        \n",
    "print(f\"SCE:            {utils.format_ci(results['sce'], scale=100)}\")\n",
    "print(f\"Ada-SCE:        {utils.format_ci(results['ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE:     {utils.format_ci(results['cc_ada_sce'], scale=100)}\")\n",
    "print(f\"CC-Ada-SCE-RMS: {utils.format_ci(results['cc_ada_sce_rms'], scale=100)}\")\n",
    "print(f\"NLL:            {utils.format_ci(results['nll'], scale=100)}\")\n",
    "print(f\"Brier Score:    {utils.format_ci(results['bs'], scale=100)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff58630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
